---
title: "Subjective povery lines:"
subtitle: "Estimates from reported minimum income"
author: 
  - "Steven F. Koch^[Corresponding author: Department of Economics, University of Pretoria, Private Bag X20, Hatfield, South Africa; +27-12-420-5285; steve.koch@up.ac.za]"
thanks: The author would like to thank someone for their comments and suggestions. Any remaining issues rest with the author.
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  bookdown::pdf_document2: 
    latex_engine: xelatex
    dev: tikz
    keep_tex: true
    number_sections: true
    toc: false
  bookdown::gitbook: null
booktabs: yes
header-includes:
    - \usepackage{setspace}\doublespacing
    - \usepackage{dcolumn}
    - \usepackage{subcaption}
    - \pagenumbering{gobble}
abstract: \singlespacing We consider minimum income questions to examine eq scales.
---
<!-- bibliography: refs.bib 
     there seems to be a problem with the bib file, 
     but I do not understand why it arises...
     
     Error reading bibliography file refs.bib:
    (line 288, column 1):
     unexpected '@'
    
-->

<!--
    - \usepackage{draftwatermark}
\SetWatermarkText{Draft}
\AddToShipoutPictureFG{
  \AtPageCenter{% or \AtTextCenter
    \makebox[0pt]{\rotatebox[origin=c]{45}{%
      \scalebox{5}{\texttransparent{0.3}{Draft}}%
    }}
  }
}
-->

<!-- subject: JEL Classifications I15, J21
thanks: The authors would like to thank someone. 
csl: empirical-economics.csl 
-->

```{r global_options, include=FALSE, cache=FALSE}
knitr::opts_chunk$set(cache=TRUE,
                      echo=FALSE,
                      autodep=TRUE,
                      message=FALSE,
                      warning=FALSE,
                      #dev='tikz',
                      dev='pdf',
                      out.width='80%',
                      out.height='80%',
                      fig.align='center')

def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
  x <- def.chunk.hook(x, options)
  ifelse(options$size != "normalsize", paste0("\\", options$size,"\n\n", x, "\n\n \\normalsize"), x)
})

knitr::opts_knit$set(kable.force.latex = TRUE)

library(tidyverse)
library(haven)
library(lubridate)
library(kableExtra)
library(np)    
library(nnet)
library(AER)
library(ivreg)
library(sandwich)
library(REndo)
library(qwraps2)
  options(qwraps2_markup = "latex")
library(stargazer)
library(MASS)


options(scipen = 999,
        np.messages=FALSE)

set.seed(42)
num.boot <- 1499 
num.splits <- 5000
q1 <- 0.025
q2 <- 0.975
nmulti <- 20

### Working Directory
#setwd('/Volumes/GoogleDrive/My Drive/Inequality/EqScalesFood')
```

```{r some-functions}
### Some useful functions ###

CM <- function(cm) {
  factor.values.eval <- colnames(cm)
  CM <- matrix(0,nrow(cm),nrow(cm))
  rownames(CM) <- rownames(cm)
  colnames(CM) <- rownames(cm)
  for(i in 1:ncol(cm)) CM[,(1:nrow(cm))[rownames(cm)==factor.values.eval[i]]] <- cm[,i]
  return(list(CM=CM,CCR=sum(diag(CM))/sum(CM)))
}

## this is a bit silly, but is driven by the difference in names between 
## prediction and model... Could also change the model data naming...
CM.logit <- function(cm) {
  factor.values.eval <- rownames(cm)
  CM <- matrix(0,nrow(cm),nrow(cm))
  rownames(CM) <- rownames(cm)
  colnames(CM) <- rownames(cm)
  for(i in 1:ncol(cm)) CM[,(1:nrow(cm))[rownames(cm)==factor.values.eval[i]]] <- cm[,i]
  return(list(CM=CM,CCR=sum(diag(CM))/sum(CM)))
}

stars <- function(x){
  case_when(x >=0 & x <= 0.005 ~ "$^a$", 
            x >=0 & x <= 0.01 ~ "$^b$",
            x >=0 & x <= 0.05 ~ "$^c$",
            x >=0 & x <= 0.1 ~ "$^d$",
            x>0.1 ~ "")
}

ctab <- function(sm){
  mm <- summary(sm,vcov=vcovHC(sm))
  modsum <- mm$coefficients
  n <- rownames(modsum)
  ses <- paste0("(",formatC(modsum[,2],format="f",digits=3, drop0trailing = F),")")
  z <- stars(modsum[,4])
  betas <- paste0(formatC(modsum[,1],format="f",digits=4, drop0trailing = F),z)
  t1 <- tibble(n=n,b=betas,s=ses) %>%
    pivot_longer(!n,names_to="params",values_to = "results")
}

nlstab <- function(sm){
  modsum <- sm$parameters
  n <- rownames(modsum)
  CIs <- paste0("(",format(modsum[,1]-1.96*modsum[,2],digits=1,nsmall=2)," -- ",
                format(modsum[,1]+1.96*modsum[,2],digits=1,nsmall=2), ")")
  betas <- format(modsum[,1],digits=1,nsmall=4)
  t1 <- tibble(n=n,b=betas,s=CIs) %>%
    pivot_longer(!n,names_to="params",values_to = "results")
}

ivctab <- function(sm){
  mm <- summary(sm)
  modsum <- mm$coefficients
  n <- rownames(modsum)
  ses <- paste0("(",formatC(modsum[,2],format="f",digits=3, drop0trailing = F),")")
  z <- stars(modsum[,4])
  betas <- paste0(formatC(modsum[,1],format="f",digits=4, drop0trailing = F),z)
  t1 <- tibble(n=n,b=betas,s=ses) %>%
    pivot_longer(!n,names_to="params",values_to = "results")
  modnost <- sm$diagnostics
  nn <- rownames(modnost)
  degfree1 <- as.character(modnost[,1])
  z1 <- stars(modnost[,4])
  ivstat <- paste0(formatC(modnost[,3],format="f",digits=3, drop0trailing = F),z1)
  t2 <- tibble(n=nn,params=degfree1,results=ivstat)
  t <- rbind(t1,t2)
}

sptab <- function(sm){
  modsum <- sm
  n <- rownames(modsum)
  colnames(sm) <- c("betas","ses")
  tt <- sm[,1]/sm[,2]
  pp <- 2*pnorm(-abs(tt))
  n <- rownames(modsum)
  ses <- paste0("(",format(modsum[,2],digits=1,nsmall=3),")")
  z <- stars(pp)
  betas <- paste0(format(modsum[,1],digits=1,nsmall=4),z)
  t1 <- tibble(n=n,b=betas,s=ses) %>%
    pivot_longer(!n,names_to="params",values_to = "results")
}

estab <- function(sm){
  sm.all <- sm
  sm <- as.matrix(sm)
  n <- paste0(sm[,1]," ",sm[,2])
  ses <- paste0("(",formatC(as.numeric(sm[,4]),format="f",digits=0, drop0trailing = F),")")
  #z <- stars(sm[,4]) - not the right function, and not going to include.
  sm3.form <- formatC(as.numeric(sm[,3]),format="f",digits=0)
  #betas <- paste0(sm3.form,z)
  t1 <- tibble(n=n, b=sm3.form,s=ses) %>%
    pivot_longer(!n,names_to="result-type",values_to = "results") %>%
    separate(n, into =c("adults","kids"))
  estab.out <- t1[,c(1,2,4)]
}

only_perc <- function(x,
                   digits = getOption("qwraps2_frmt_digits", 2),
                   na_rm = FALSE,
                   show_denom = "ifNA",
                   show_symbol = TRUE,
                   markup = "latex") #getOption("qwraps2_markup", "latex")) 
                   {
  d <- sum(!is.na(x))
  n <- sum(x, na.rm = na_rm)
  p <- frmt(100*n/d, digits)

  if (show_denom == "never") {
    rtn <- paste0(p,"%")
  } else {
    if (show_denom =="always" | any(is.na(x))) {
      rtn <- paste0(frmt(as.integer(n)), "/", frmt(as.integer(d)), " (", p, "%)")
    } else {
      rtn <- paste0(p,"%")
    }
  }

  if (!show_symbol) {
    rtn <- gsub("%", "", rtn)
  }


  if (markup == "latex") {
    rtn <- gsub("%", "\\\\%", rtn)
  }

  return(rtn)
}

quadRoots <- function(a, b, c) {

print(paste0("You have chosen the quadratic equation ", a, "x^2 + ", b, "x + ", c, "."))

discriminant <- (b^2) - (4*a*c)

  if(discriminant < 0) {  # if discriminant is less than zero i.e no real roots
    return(paste0("This quadratic equation has no real numbered roots."))
  }
  else if(discriminant > 0) { # If discriminant is greater than 0 ie real roots
    x_int_plus <- (-b + sqrt(discriminant)) / (2*a)
    x_int_neg <- (-b - sqrt(discriminant)) / (2*a)

    return(paste0("The two x-intercepts for the quadratic equation are ",
                  format(round(x_int_plus, 5), nsmall = 5), " and ",
                  format(round(x_int_neg, 5), nsmall = 5), "."))
  }
  else #discriminant = 0  i.e only one root 
    x_int <- (-b) / (2*a)
    return(paste0("The quadratic equation has only one root. This root is ",
                  x_int))
}
```


```{r lcs}

# LCS data
person <- read_dta(file = "../data/201415/lcs-2014-2015-persons-final-v1.dta")
total <- read_dta(file = "../data/201415/lcs-2014-2015-total-v1.dta")
household <- read_dta(file = "../data/201415/lcs-2014-2015-households-v1.dta")
#household.assets <- read_dta(file = "data/lcs-2014-2015-household-assets-v1.dta")

# hhsize, number of kids (age < 15) in each household
person1 <- person %>%
  group_by(UQNO) %>%
  summarise(hhsize = n(), # household size by appearance times of each ID
            kids = sum(Q14AGE < 15), # number of child (age<15)
            adults = hhsize - kids
            ) %>%
  mutate(UQNO = as.character(UQNO))

person2 <- person %>%
  dplyr::select(UQNO, PERSONNO, Q12SEX, Q13POPGROUP, Q14AGE, Q17MARITAL, Q21HIGHLEVEL, 
         province_code, SETTLEMENT_TYPE) %>%
  filter(PERSONNO==1, 
         Q17MARITAL != 9,
         Q21HIGHLEVEL != 31,
         Q21HIGHLEVEL != 32,
         Q21HIGHLEVEL != 99) %>%  
  transmute(UQNO = as.character(UQNO),
            age = Q14AGE,
            hhh.dummy = ifelse(Q12SEX==1,1,0),
            hhh.male = as_factor(Q12SEX),
            ethnic = as_factor(Q13POPGROUP),
            ba = ifelse(Q13POPGROUP==1,1,0),
            cl = ifelse(Q13POPGROUP==2,1,0),
            as = ifelse(Q13POPGROUP==3,1,0),
            wh = ifelse(Q13POPGROUP==4,1,0),
            wc = ifelse(province_code==1,1,0),
            ec = ifelse(province_code==2,1,0),
            nc = ifelse(province_code==3,1,0),
            fs = ifelse(province_code==4,1,0),
            kz = ifelse(province_code==5,1,0),
            nw = ifelse(province_code==6,1,0),
            gp = ifelse(province_code==7,1,0),
            mp = ifelse(province_code==8,1,0),
            lp = ifelse(province_code==9,1,0),
            province = as_factor(province_code),
            urbfor = ifelse(SETTLEMENT_TYPE==1,1,0),
            urbinf = ifelse(SETTLEMENT_TYPE==2,1,0),
            tradit = ifelse(SETTLEMENT_TYPE==4,1,0),
            rurfor = ifelse(SETTLEMENT_TYPE==5,1,0),
            settle = factor(SETTLEMENT_TYPE, levels = c(1,2,4,5),
                            labels=c("Urban Formal","Urban Informal",
                                     "Traditional Area","Rural Formal")),
            marital = as_factor(Q17MARITAL),
            education = factor(Q21HIGHLEVEL, levels = c(98,1:25,27,28:29,26,30),
                              labels=c("none",rep("nqf0",9),"nqf1","nqf2","nqf3",rep("nqf4",2),
                                       "nqf1","nqf2","nqf3",rep("nqf5",3), rep("nqf4",2),"nqf5",
                                       "nqf6",rep("nqf7",2),rep("nqf8",2),rep("nqf9-10",2))),
            Q21HIGHLEVEL) %>%
  droplevels() 

# household level variables
house.df <- household %>%
  dplyr::select(
    UQNO, income_inkind, expenditure_inkind, SURVEYDATE, Q229NETINCOME, 
    Q6105IMAGINE, Q116PRESENT, hholds_wgt) %>%
  filter(Q6105IMAGINE != 9, Q116PRESENT != 9) %>% ## loses 493 obs..
  transmute(
    UQNO = as.character(UQNO),
    wt = hholds_wgt,
    surveydate = dmy(SURVEYDATE),
    surveymonth = month(surveydate),
    surveyyear = year(surveydate),
    x = as.numeric(expenditure_inkind), 
    # the value of expenditures including in kind expenditure incurred by 
    # households for 12 months inflated/deflated to April 2015 using CPI
    x.month = x/12, #Monthly total expenditure
    y = as.numeric(income_inkind),  
    # 63 observations have 0 values... length(which(house.df$y==0))
    # also deflated/inflated to April 2015
    y.month = y/12,
    lnx = log(x.month),
    lny = log(y.month),
    minq = Q229NETINCOME, 
    # 466 zero values (after dropping the 493 above) ... length(which(house.df$minq == 0))
    lnminq = log(minq),
    ladder = Q6105IMAGINE,
    wealth = as_factor(Q116PRESENT)
  ) %>%
  filter(is.finite(lny),
         is.finite(lnx),
         is.finite(lnminq)) %>%  # Not sure this affects the final lcs data, though
  droplevels()
  


#merge above dataframes to get a dataframe LCS2014
LCS2014 <- person1 %>%
  full_join(person2, by="UQNO") %>%
  full_join(house.df, by="UQNO") %>%
  drop_na() %>%
  filter(adults > 0,
         adults <= 6,
         kids <= 4)
## It appears that we lose 312 observations for missing values, 
## we lose 556 in total; the extra coming from limiting adults and kids in hh
  
# save image
#save.image("data/LCS2014.Rdata")

# save a single data frame: LCS2014
# This gets used by the NP files.
#save(LCS2014, file="../data/LCS2014df.Rdata")

rm(person,household,total)

data.full <- LCS2014 %>%
  mutate(ao = ordered(adults),
         ko = ordered(kids),
         k0 = 1*(kids==0),
         k1 = 1*(kids==1),
         k2 = 1*(kids==2),
         k3 = 1*(kids==3),
         k4 = 1*(kids==4),
       #  k5 = 1*(kids==5),
      #   k6 = 1*(kids==6),
         a1 = 1*(adults==1),
         a2 = 1*(adults==2),
         a3 = 1*(adults==3),
         a4 = 1*(adults==4),
         a5 = 1*(adults==5),
         a6 = 1*(adults==6),
       #  a7 = 1*(adults==7),
      #   a8 = 1*(adults==8),
         lnx.sq = lnx^2,
         lny.sq = lny^2,
         age.sq = age^2)


base.data <- data.full %>%
  dplyr::select(UQNO,ko, ao, age, age.sq, hhh.male, 
                k0,k1,k2,k3,k4,a1,a2,a3,a4,a5,a6,
                ethnic, province, settle, marital, education, 
                lnx, lnx.sq, lny, lny.sq, minq, lnminq) %>%
  transmute(lnx, lnx.sq, lny, lny.sq, ko, ao,
            k0,k1,k2,k3,k4,a1,a2,a3,a4,a5,a6, minq, lnminq,
            age = as.integer(age),
            age.sq = as.integer(age.sq),
            hhh.male = as.factor(hhh.male),
            ethnic = as.factor(ethnic),
            province = as.factor(province),
            settle = as.factor(settle),
            marital = as.factor(marital),
            education = as.factor(education)) 

main.df <- base.data
## Some parameters
n <- nrow(main.df)
n2 <- 24
n1 <- n-n2

#save(main.df, file="data/main.Rdata")
```


```{r lcs-np-data, dependson="lcs"}

load("../data/np-minq-results-main.Rdata")

## This should have been saved with the data, while running the np analysis.
## Unfortunately, it was not, so the code from the np fle is copied here
## df is only the data frame for the np analysis, nothing else!
df <- LCS2014 %>%
  dplyr::select(lnx, lny, adults, kids, hhh.male, marital, ethnic, province, settle, education,
         lnminq)

## Vectorise for np package?
## Here we are using factors and ordered
df$lnminq <- as.vector(df$lnminq)
df$kids1 <- factor(df$kids)
df$adults1 <- factor(df$adults)
df$kids2 <- ordered(df$kids)
df$adults2 <- ordered(df$adults)


```

\newpage
\pagenumbering{arabic}

# Introduction??

@grodnersalas2017 - there is an update of that -  describe the information content of equivalence scales that can be captured from minimum needs income...  @blundelllewbel1991 and  describe the information content in equivalence scales. In order to make comparisons across households, @lewbel1989 describes ordinal level comparability, while @blackorbydonaldson1993 describe ordinal full comparability plus. These ideas relate to the ability to compare utility across households; the underlying information basis depends on the ability to calculate equivalence scales, and is only relevant for monotone transformations of utility that keep the scale constant. Most commonly, this is done through an Independence of Base assumption [@lewbel1989] or an Equivalence-Scale Exactness [@blackorbydonaldson1993] assumption, which are the same. Such restrictions are often rejected [@pendakur1999]^[I really need to do some checking on this with the SA data... I have started to do some of this analysis, but plausibly need to do more...]; A slightly weaker assumption can lead to general equivalence scales, which are not uniform across the entire population. One such weakening is to allow for monotone transformations, but only at a specific level of utility. In essence, making such a comparison relies on ordinal local comparability [@grodnersalas2017], and leads to local equivalence scales. 

One might wonder whether such scales are even useful. However, @blundelllewbel1991 suggested one solution that would help in the identification of demand systems, which @blackorbydonaldson1993 also suggested, arguing it was very relevant for policy. The suggestion was we should focus attention on utility levels that allow individuals to make ends meet, referring to this as the minimum level of utility. Furthermore, the poverty line is the level of income assumed/required for a household to reach that minimum level of utility.  

## Intro from Bernice

Over the years the measurement of poverty and inequality has become a point of focus for economists and policymakers, particularly in countries like South Africa, where the poverty rates remain high, and income disparities are stark (Leibbrandt et al., 2012). In determining poverty rates, the method employed by Statistics South Africa is an absolute poverty line where they set three primary thresholds: the upper-bound, lower-bound and food poverty lines (Statistics South Africa, 2022). These lines are constructed using the cost-of-basic-needs approach which links welfare to the consumption of goods and services, basically computing the cost of basic needs based on the reported consumption expenditures (Statistics South Africa, 2021). Money-metric measures, such as the South African poverty line, aid in providing a tool for the statistical measurement of poverty. However, the use of an absolute approach to poverty establishes a fixed amount that, even after accounting for inflation, does not alter over time to reflect changes in general living standards or costs. 

Some studies (Seekings, 2007; Meth & Dias, 2004), although underlining the importance of money-metric measures in setting a threshold, argue that poverty measures based on income and expenditure ignore the non-income components of living standards. Others argue that money-metric measures are insufficient for evaluating well-being as they are insensitive to fluctuations that are caused by differences in household size and other factors within a household (Posel et al., 2020; Ravallion & Lokshin, 2002; Zwane, 2018). Additionally, money-metric measures may be inaccurate in assessing the degree of poverty if the expenditures or income measures used are not closely linked to the various aspects of the household’s living standards (Posel & Rogan, 2014). Thus, when using income or expenditure to assess economic well-being, it is important to consider individual or household differences in characteristics that affect needs. These differences could be household size and composition, regional cost of living differences and subjective perceptions of well-being (Daley et al., 2020). Some researchers have attempted to rectify this by accounting for household structure and regional differences in assessing multidimensional poverty in South Africa (Megbowan, 2018; Fransman & Yu, 2019). However, this approach does not account for economies of scale in income or expenditure (for example, a family of two may require more money than a single person but not twice as much), nor does it account for the difference in requirements for adults versus children (Daley, et al., 2020).

One alternative way is by employing a subjective income poverty approach, which is based on the “happiness and economics” literature (Ravallion, 2014; Ferrer-i-Carbonell & Van Praag, 2003). This subjective income poverty approach uses responses to the Minimum Income Questions (MINQ) and seeks to close the gap by assessing individuals’ perceptions of the minimum required income for an acceptable standard of living (Goedhart et al., 1977). The MINQ lets households report the minimum net income they estimate is necessary to “get by”, capturing a broader range of welfare components that differ by family type, size and geographic location (Byaruhanga et al.,2017; Wang, et al., 2020). Assessing subjective poverty can provide additional insights into how households perceive their economic well-being in relation to their actual income, highlighting disparities that objective measures might miss. This is because subjective measures are not dependent on pre-determined, expert-derived poverty thresholds (Ravallion & Lokshin, 2001). Using the subjective poverty approach gives the benefit of not only better understanding some of the roles and robustness of various determinants of poverty but can also help us detect the key determinants that policy initiatives should focus on (Dartanto & Otsubo, 2013). 

Despite the existing body of research on poverty in South Africa (Woolard & Leibbrant, 1999; Daley et al., 2020; Posel & Rogan, 2014), there are some gaps remaining regarding the role of household dynamics and regional disparities. There are also gaps in what these differences mean in determining a subjective poverty level. Thus, the purpose of this study is to better understand how subjective income levels vary across South African households as well as using the MINQ to capture these differences. This research builds on earlier studies that use the MINQ to explore subjective poverty (Goedhart et al., 1977; Kapteyn et al., 1988). This study explores how a households’ perceived minimum income can vary due to differences in the household size, composition, geographic location and the settlement type. This research aims to provide new insights into the evolving socio-economic landscape of South Africa by using the 2014/2015 living Conditions survey. This work follows a similar method to Wang et al., (2020), in which an OLS regression is computed, and the coefficients are then utilized to estimate subjective poverty lines.

The findings reveal that household composition plays a critical role in shaping income needs, where households with one of more adults have higher subjective poverty levels, and households with three or more adults have lower levels. The results vary with the effect of children within a household, thus further research would be needed to see the effect of children at different ages. The results further highlight significant disparities in subjective poverty thresholds, with households in urban formal areas requiring higher minimum incomes compared to rural and traditional areas
The structure of the paper is as follows: Section 2 is a review of the literature that looks at the early theories of using subjective measures, like the minimum income question, to gauge people's perceptions of poverty. It also looks at the studies of subjective poverty carried out in South Africa and the shift to using the minimum income question in estimating equivalency scales to better understand changes within households. The data and methodology used in the study are then covered in Section 3, and the results and discussion are covered in Section 4. The conclusion, included in Section 5, provides a summary of the main conclusions of the study.

## Lit Review from Bernice

One of the earliest estimations of subjective poverty measures (Goedhart, et al., 1977) introduces the idea of developing a poverty line using the Minimum Income Question (MINQ). The authors argue that people's opinions of the minimal income required are positively correlated with their own income and family size. As a result, income levels were found to vary according to family size. Kapteyn et al. (1988) extended this body of work by demonstrating that the MINQ can be utilized as a tool for evaluating subjective poverty by stressing its ability to capture an individual's perceived income adequacy. The reason for this is that by asking people what their minimum income is, it can take into consideration differences in living expenses that are driven by demographics and geography. This approach is also linked to the subjective welfare function of income, as proposed by Van Praag (1971), which attempts to capture how individuals perceive and evaluate their well-being in relation to income levels rather than assuming a one-size-fits-all welfare approach.

Over time other studies on the use of subjective measures of poverty using the MINQ have further reinforced early theories by showcasing some advantages in using this method. For example, Flik & Van Praag (1991) highlighted the utility of subjective data in understanding poverty dynamics across heterogenous populations. Additionally, Rojas (2008) utilizes the MINQ question was to measure subjective poverty and finds that a large number of households that are deemed "non-poor" by money-metric metrics still perceive themselves as impoverishment because of factors beyond income such as household composition and regional cost variations. Other studies that used the same methodology found that the more individuals there are in a household, the more income is needed to maintain the household's standard of living when (Vermeulen, 2002; Lanjouw & Ravallion, 1995). These studies demonstrate how subjective metrics of poverty could pick up on elements of other elements of poverty that objective metrics can overlook. 

The MINQ has certain limitations when it comes to poverty assessments. Studies that assess subjective measures of poverty have the disadvantage of potentially being inaccurate because they may reflect respondents' aspirations rather than their actual living conditions, even though respondents may self-report their levels of poverty (Kapteyn et al., 1978; Ravallion & Lokshin, 2002; Sen, 1983). It is recommended that subjective poverty studies be utilized in conjunction with money-metric data rather than in substitute of them in order to provide a more composite measure of poverty (Posel & Rogan, 2014).

In some instances, poverty and inequality analysis rely heavily on equivalence scales, as these scales enable comparisons of income from households of different size and composition (Falter, 2004). An equivalence scale can be defined as a scale that adjusts household income to the degree of economic efficiency of household size and compares welfare levels for each household receiving from income in the same standard (Urakawa & Tokudomi, 2019). There are different approaches to estimating equivalence scales, including expert-based scales, demand system derived scales and subjective equivalence scales.

There is a growing body of literature that uses data on subjective perceptions of economic well-being to derive equivalence scales. Examples of these studies include using income evaluation or minimum income questions (Bishop et al, 2014; Garner & De Vos, 1995; Mysikova et al., 2021; Kapteyn et al., 1988). The subjective approach to estimating equivalence scales recognizes that poverty lines are based on an individual or households’ perception on what constitutes an acceptable standard of living in a certain society (Ravallion, 1992). One approach in estimating equivalence scales is the intersection approach, introduced by Goedhart et al., (1977), where the individuals’ perceptions of their minimum income needed aligns with their actual income. In several of these studies, the MINQ is used to estimate the income needed for a household of a specific composition to reach what they consider an acceptable quality of living. These studies (Bishop et al., 2014; Mysikova et al., 2021) typically use a single-adult reference home. 

Bishop et al. (2014) calculated subjective equivalency scales for Euro Zone nations in comparison to objective OECD scales and discovered that subjective scales exhibit larger economies of scale within a household than objective scales. Furthermore, they discovered that subjective measures suggest a decreasing marginal cost of adding children, whilst the OECD and NRC scales show a constant marginal cost of children. Mysikova et al. (2021) employed a different technique, utilizing the MINQ to first estimate subjective poverty lines, which were then used to generate equivalency scales for EU countries and compared them to the modified OECD scales. Similar to the findings of Bishop et al. (2014), they discover that subjective scales exhibit greater economies of scale than modified OECD scales. They also discover that wealthy countries have superior economies of scale due to their stronger welfare programs. Both of these investigations are based on the intersection methodology established by Goedhart et al. (1977).  Because of the intersection methodology, there ends up being a convergence between subjective equivalence scales and subjective poverty lines as both of these poverty assessments are mainly based on the MINQ.

In South Africa, much of the equivalency scale research uses a parametric or semiparametric scale approach to quantify individual or household income or expenditure (Posel et al., 2016; Rogan, 2012; Yatchew et al., 2003; Posel et al., 2020; Koch, 2022). Posel et al., 2020 estimated equivalence scales for South Africa using the Engel technique, which takes into account the share of a household's expenditure allocated to food. They found that compared to non-African households, African households experience larger economies of scale in household consumption. They also found that children consume less than adults do. Using a different data set and a similar Engel technique, Koch (2022) estimated equivalence scales based on a household's portion of the food budget using the 2014-2015 Living Conditions Survey. According to the study's findings, food shares are higher in bigger households at almost every spending level; however, the increase seems to be less pronounced as family sizes increase, suggesting that there may be household economies of scale. In contrast to Posel et al. (2020), their data also shows that households with youngsters spend comparatively more than households with just adults. However, when it comes to subjective equivalence scales in South Africa, there is limited research available. Among  this research is that by Koch (2023), which focuses on the adequacy of basic needs using data from the 2014–2015 Living Conditions Survey. In order to compare subjective and objective measures of poverty, the study uses a households self-assessed adequacy of food, clothing and housing to estimate subjective poverty scales. Although these scales offer a different view on poverty in South Africa, they mostly rely on objective methods or subjective data instead of the MINQ.

Subjective poverty assessments in South Africa that are based on the MINQ are also limited, with subjective poverty studies looking at either self-assessments of their economic status (Posel & Rogan, 2014), assessments of their life satisfaction (Moller and Saris, 2001) or the determinants of subjective poverty (Bila & Biyase, 2022). Moller and Saris (2001) used the 1995 Quality of Life Trends study to assess subjective poverty with the aim of examining subjective well-being across racial groups. Their study found that there were significant racial inequalities within the country, with Black South Africans reporting higher levels of subjective poverty compared to other racial groups. Bookwalter and Dalenburg (2004) used the 1994 South African Labour and Development Research Unit (SALDRU) data in their analysis of subjective poverty where they found that transportation and housing significantly influence subjective well-being, especially for rural households Posel & Rogan (2014) used the 2008-2009 LCS where respondents were asked to rate themselves from very poor to wealthy to estimate subjective poverty lines in South Africa. Their findings reveal that a household’s self-assessed level of poverty increases as the size of the household increases. Additionally, they found that larger families benefit from economies of scale and resource sharing and that there can be differences in the cost of living due to some wealthier provinces having higher costs of living. Bila & Biyase (2022) looked at the determinants of subjective poverty using the 2014-2015 LCS, with the aim of  examining the impact of gender, education, marital  status and locality on subjective poverty. They found that factors such as landownership and access to services have an effect on rural households’ subjective poverty. Whereas urban households are more likely to be affected by unemployment and health conditions. In general, they discovered that in South  Africa, variables like income, employment, household size and geographic location play a role in how  poverty is defined.

Despite these contributions, South African research does not have a focused examination of subjective poverty lines using the MINQ. Most studies rely on alternative subjective measures, leaving gaps in our understanding of how minimum income perceptions vary across household consumptions and regions. This study aims to fill this gap by using the using the 2014-2015 LCS to estimate subjective poverty lines for households based on the MINQ. 

# Data

## Discussion from Bernice

The data used in this study is from the 2014-2015 South African Living Conditions Survey (LCS) which was collected by Statistics South Africa. The survey contains data regarding household and individual variables such as household assets, household expenditures, employment statuses, gender and age. Although there are other surveys in South Africa that look at these variables such as the General Household Survey, however the LCS contains the MINQ question which is an important part of the analysis of this paper. 

Three data files from the LCS were combined to create the data used in the analysis: the households data file, the individual’s data file, and the total data file. An initial total of 23380 households was obtained by combining these three datasets. The "age" variable in the dataset was used to generate the Children and Adults data, classifying all individuals under the age of 15 as children and all adults living in a home over the age of 15 as adults. After merging, the dataset was filtered to remove zero values from the MINQ variable, which eliminated 504 observations, and zero values from the income-in-kind data, which eliminated 55 observations, leaving 22821 observations. The list of variables used in this analysis are shown in Table 7 1 which can be found in the Appendix. 

The analysis' dependent variable is the bare minimum of income that households require to survive. At first, the survey responses were presented as annual figures. The data was first converted to monthly numbers and then log transformed for the analysis. This was carried out because the MINQ distribution appears to be heavily skewed to the right, with a lengthy tail that extends to higher values. This suggests that while the majority of households report having modest minimal incomes, some have extremely high minimum income requirements, resulting in outliers. This is in line with the high-income inequality prevalent in the Country. However, the distribution of the logged minq seems to be more normally distributed and more symmetrical. Thus, the log transformation of MINQ compresses the scale of larger values which makes it easier to analyse and interpret the data. 

Log transformations are important in trying to stabilize variance as well as mitigate the impact of extreme values, particularly when analysing income data which often exhibits skewness (Gujarati, 2009). Therefore, all values shown in the analysis are shown at the monthly level.


The independent variable is household income in kind. This variable was likewise changed into a monthly value, which was then log transformed. This method is in line with research conducted by Ravallion & Lokshin (2002). They focused on income than expenditure to determine poverty levels. The decision to focus on income is based on the fact that it offers a perspective of a household’s situation by including both earned and in-kind sources of income. Furthermore, in assessing minimum requirements, income acts as a gauge of a household’s ability to attain a satisfactory quality of life as it represents the overall resources, at their disposal, for fulfilling crucial costs.

Control variables are also added to the analysis. These control variables represent the different household demographics such as household size and location. This is done to assess the relationship that different household demographics have to the minimum income needs. These variables include:
+   Household Composition: the proportion of adults and children living in the household. This is evaluated in two parts. The first one uses the household of one adult and no children as the basis for the analysis and looks at the number of adults and children as dummies. The second is where adults and children are viewed as a continuous variable. In the dummy variable approach, the number of children and adults within a household are capped 6 because the number of households with more than 6 children and 6 adults is relatively small within the dataset.
+   Geographical Variables: The different provinces within the country are also assessed, with the baseline province being households in the Northwest, and 
+   Location Variables: Settlement types are also factored in where the baseline are households in rural formal areas



# Methods

## Subjective poverty lines and marginal costs

We apply fairly standard methods, assuming both a parametric and nonparametric relationship \eqref{eq:nprelation} between minimum income $(\underline{Y})$, actual income $(Y)$, household demographic characteristics $(D)$ and other characteristics related to household decisions, such as location and marital status, $(Z)$. Equation \eqref{eq:nprelation} represents the general structure, which assumes no functional form. 
\begin{equation}
\label{eq:nprelation}
\ln \underline{Y} = f(Y,D,Z)
\end{equation}
We tighten the functional form assumption, first, assuming simple linearity, as in \eqref{eq:linindex}.
\begin{equation}
\label{eq:linindex}
\ln \underline{Y} = \alpha + \beta \ln Y + \sum_j \delta_j D_j + \sum_j \zeta_j Z_j 
\end{equation}
Finally, we extend that to allow for a potential quadratic relationship, as in \eqref{eq:quad}. 
\begin{equation}
\label{eq:linindex}
\ln \underline{Y} = \alpha + \beta \ln Y + \gamma \left( \ln Y \right) + \sum_j \delta_j D_j + \sum_j \zeta_j Z_j 
\end{equation}

Subjective poverty lines are described as fixed points [@Goedhartetal1977], where $\ln \underline{Y} = f(\ln Y, D, Z)$. Under linearity, that fixed point occurs at the intercept, adjusted for the regression slope.
\begin{equation}
\label{eq:linear-spl}
\underline{Y} =   \frac{\alpha + \sum_j \delta_j D_j + \sum_j \zeta_j Z_j }{1-\beta} 
\end{equation}
With a quadratic term in the regression, the fixed point is determined by the solution to the quadratic formula, where we will limit our attention to real roots.^[At this point, I am not sure if we will have complex root "problems". If we do not, we just need to mention that. If we do, we will have to comment about how common the violation is, and what we had to do to eliminate it.] For the general equation, we will apply simulation methods, searching for the value of $\ln \underline{Y} = f(\ln \underline Y, D, Z)$, conditional on $D$ and $Z$. 

Technically, we net out all of the $Z$ factors; they are included in the regression, but are not allowed to vary for the calculation of subjective poverty. However, it is possible to calculate different subjective poverty lines for different regions of the country, or other subgroups by altering the calculation structure.

<!--
Rearranging to find the intersection - goedhart - yields the subjective poverty line, as a function of the demographic and other characteristics \eqref{eq:spl}.

\begin{equation}
\label{eq:spl}
\underline{Y} =  \exp \left( \frac{\alpha + \sum_j \delta_j D_j + \sum_j \zeta_j Z_j }{1-\beta} \right)
\end{equation}

From these subjective poverty lines, marginal child and adult costs can be derived for each additional household member $(h \in \{a,k\})$, where $a$ and $k$ refer to adult and child, respectively, while $\underline{Y}^*$ is the reference household, which we will define as having one adult and zero children. **Is this independent of the number of adults and children already in the house? As before, we can turn off the "other" variables?** 

\begin{equation}
\label{eq:margcost}
M(h) = \frac{\underline{Y}(h) - \underline{Y}(h-1) }{\underline{Y}^*}
\end{equation}


The linear model specified yields marginal costs that are partially independent of the underlying size of the household, and, therefore, may not be appropriate. *Are they partially independent? Not really, because of the exponential functions... The SPLs are partially independent, though.* Specifically, it is possible the that the marginal cost of a first child is larger/smaller in a household with two adults than in a household with one adult. Therefore, we also estimate the nonparametric model in \eqref{eq:nprelation}. To capture the intersection, we apply numeric methods, because the inverse of an unspecified function cannot be determined. 

*Option 1:* First, we fix $D$ and $Z$ to create a data subsample. We use the fixed values of $D$ and $Z$, as well as the observed $\ln Y$ values to predict $\hat{f}$ for all households in the subset. We then choose the $\ln Y$ that is closest to the fitted value, as the subjective poverty line for that household type. *Worry:* this value may not be all that "close". 

*Option 2:* First, we fix $D$ and $Z$. Second, we simulate $\ln Y$ across a wide range. We use the simulated data to predict $\hat{f}$ for all households in the subset. We then choose the simulated $\ln Y$ that is closest to the fitted value, as the subjective poverty line for that household type. *Worry:* this value may not match what households say they spend?

\begin{equation}
\label{eq:nprelation2}
\ln \underline{Y} = \hat{f}(\ln Y,\tilde{D},\tilde{Z})
\end{equation}

-->

## Empirical modelling


```{r lcs-sub}

#, dependson="lcs-np-data"

# Maybe, we want to look at those whose reported values 
# are close to actual? I am not convinced I want to keep it
# How about those whose reported is above their actual?

df.data <- main.df %>%
  dplyr::mutate(min.yq = lny - lnminq) # difference between actual and reported minimum

below.df <- df.data %>%
  filter(min.yq <= 0 )          # reported income always less than reported minimum

above.df <- df.data %>%
  filter(min.yq >= 0 )          # reported income always above reported minimum

# kids limited to max 4 and adults to max 6
dfref <- cbind(k1 = 0, k2 = 0, k3 = 0, k4 = 0, 
               a2 = 0, a3 = 0, a4 = 0, a5 = 0, a6 = 0)

akmat <- base.data %>%
  dplyr::select(ao,ko,
                a1, a2, a3, a4, a5, a6, 
                k0, k1, k2, k3, k4) %>%
  unique() %>%
  arrange(ko) %>%
  group_by(ko) %>%
  arrange(ao) %>%
  ungroup()

dfalt <- akmat %>%
  dplyr::select(k1,k2,k3,k4,
                a2,a3,a4,a5,a6) 

dfdiff <- data.matrix(sweep(dfalt,2,dfref)) 
```



# Results

## Descriptives

I do need to build a table, but that should be quick.

```{r loess-plot, dependson="lcs", fig.cap = "Loess regression plot and data points: log reported minimum income against log reported income"}

main.df %>% ggplot(aes(x = lny, y = lnminq)) +
  geom_point(alpha = 0.4, color = "blue", shape = 1) +  
  #scale_shape(solid = FALSE) + 
  geom_smooth(method = "loess", color = "red", se = TRUE) +  
  labs(
   # title = "Loess regressiob plot of lo vs. lny",
    x = "Log of Monthly Income (lny)",
    y = "Log of Minimum Income (lnminq)"
  ) +
  theme_minimal()  # Use a clean theme
```


## Nonparametric regression

We begin with optimal bandwidths, which are presented in Table \@ref(tab:np-bw-table). The table presents bandwidths, based on the type of variable. In all models, monthly log income is treated continuously, while the education level of the head, gender, marital status and ethnicity are all treated as categorical factors, as are province of residence and household's urban status (settlement type). The difference across the models is the treatment of adults and kids. Under the continuous column, they are treated as continuous variables; they are treated as factors in the final two columns. Categorical, here, refers to treating the factors as unordered; they are treated as ordered - the most logical choice - in the final column.^[Why logical here?] 

Although bandwidths are not average effects, they do offer insight into the underlying nonparametric relationship. In the case of continuous variables, the optimal bandwidth selection method uncovers irrelevant variables (Li, Racine and Hall?), and that irrelevance is implied by large bandwidths. For both adults and children, whose range is in the single digits, a bandwidth out to six digits far exceeds the underlying data range, and, therefore, is suggestive of statistical irrelevance. In the case of categorical variables, bandwidths are more intuitively compared to category proportions. In the case of a binary factor, for example, a bandwidth close to zero is suggestive of a relevant variable. Thus, both categorical models -- columns 2 and 3 -- suggest the opposite, bandwidths closer to one than zero: variables that are bordering on irrelevance. 

```{r np-bw-table, dependson="lcs-np-data", results="asis"}

# pulling the bandwidths from the np analysis
bandwidths <- cbind(bw1$bw, bw2$bw, bw3$bw) %>%
  round(digits = 5)

# there are two that need to be separately rounded, 
# because they are orders of magnitude bigger
bandwidths[3:4,1] <- format(bandwidths[3:4,1],digits=1)

# names of the matrix for the table...
#colnames(bandwidths) <- c("Continuous","Categorical","Ordered")
rownames(bandwidths) <- c("Log income","Education qualification","Adults in HH","Kids in HH",
                          "Male household head","Marital status","Ethnicity","Province","Settlement type")


kable(bandwidths, format = "latex", align='rrr',
      row.names = T,
      booktabs=TRUE, escape=FALSE, longtable=FALSE,
      linesep="",
      caption="Nonparmetric optimal bandwidth estimates from regressions of (log) reported minimum income against household level variables.",
      col.names=c("Variables","Continuous","Categorical","Ordered")) %>%
  #add_header_above(c(" "=2, "Household Income"=3, "Household Expenditure" = 3)) %>%
  kable_styling(latex_options = c("striped", "hold_position", position="center")) %>%
  footnote(general = "Optimal bandwidths arising from least squares cross-validation. Continuous refers to both children and adults be modeled as continuous variables, while categorical models them as unordered factors, and ordered assumes the factors are ordered.", escape=FALSE, general_title="",threeparttable=TRUE) 

```

To offer additional insight, we illustrate the nonparametric average effects for both adults and children in the following Figures \@ref(fig:np-bw-kids-adults-plot-1) and \@ref(fig:np-bw-kids-adults-plot-2)

```{r np-bw-kids-adults-plot, dependson="lcs-np-data",fig.cap = "Nonparametric regression plot of the gradient between adults and children in the household and reported minimum income (logs)", fig.subcap = c("Gradient for adults", "Gradient for children"), out.width = c("48%","48%")}

kids.plot.out <- plot(bw2,
                 perspective=FALSE,
                 plot.errors.method="bootstrap",
                 plot.errors.boot.num=399,
                 plot.behavior="data",
                 plot.bxp = TRUE,
                 gradients=TRUE)


bxp(kids.plot.out$rg3$bxp,boxfill = "lightblue",
    xlab = "Number of adults in household",
    ylab = "Estimated gradient of reported log minimum income (relative to one adult)")

bxp(kids.plot.out$rg4$bxp,boxfill = "lightgreen",
    xlab = "Number of children in household",
    ylab = "Estimated gradient of reported log minimum income (relative to zero children)")
```


\newpage
## Linear parametric subjective poverty lines

Estimation results from linear model suggest that there is no kid "effect"...However, there are very big education effects. So, I am going to try to match the expenditure with the minq and see if this looks any different?


```{r lineary-spl, dependson="lcs-sub"}

base.data <- df.data
model <- lm(lnminq ~ lny + k1 + k2 + k3 + k4 + 
              a2 + a3 + a4 + a5 + a6 +  age + age.sq + hhh.male + 
              ethnic + province + settle + marital + education,
            data=base.data)

b <- coef(model)[1:11] # does not count non-income and non-adult/child vars.
b1 <- b[3:11]
denom <- 1-b[2]

spl.base <-  exp( (b[1] + (dfdiff %*% b1)) * (1/denom) )

### Bootstrapping - Not the cleanest, but works
boot <- NULL
for (i in 1:399){
  ss <- sample(dim(base.data)[1],replace=T)
  dd <- base.data[c(ss),]
  lnmq.model <- lm(lnminq ~ lny + k1 + k2 + k3 + k4 + 
                     a2 + a3 + a4 + a5 + a6 +  age + age.sq + hhh.male +
                     ethnic + province + settle + marital + education,
                   data=dd)
  cc <- coef(lnmq.model)[1:11]
  cc1 <- cc[3:11]
  denomboot <- 1-cc[2]
  splboot <-  exp( (cc[1] + (dfdiff %*% cc1)) * (1/denom) )
  boot <- cbind(boot,splboot)
}

## Get Eq Scale Standard Deviations
spl.sd <- apply(boot,1,sd)

spl.linminq.yall <- akmat %>%
  dplyr::select(ao,ko) %>%
  mutate(adults = as.integer(ao), kids = as.integer(ko)-1) %>%
  add_column(spl = as.integer(spl.base), 
             spl.sd = as.integer(spl.sd)) %>%
  dplyr::select(-c(ao,ko))

```


```{r linearx-spl, dependson="lcs-sub"}

base.data <- df.data
model <- lm(lnminq ~ lnx + k1 + k2 + k3 + k4 + 
              a2 + a3 + a4 + a5 + a6 +  age + age.sq + hhh.male + 
              ethnic + province + settle + marital + education,
            data=base.data)

b <- coef(model)[1:11] # does not count non-income and non-adult/child vars.
b1 <- b[3:11]
denom <- 1-b[2]

spl.base <-  exp( (b[1] + (dfdiff %*% b1)) * (1/denom) )

### Bootstrapping - Not the cleanest, but works
boot <- NULL
for (i in 1:399){
  ss <- sample(dim(base.data)[1],replace=T)
  dd <- base.data[c(ss),]
  lnmq.model <- lm(lnminq ~ lnx + k1 + k2 + k3 + k4 + 
                     a2 + a3 + a4 + a5 + a6 +  age + age.sq + hhh.male +
                     ethnic + province + settle + marital + education,
                   data=dd)
  cc <- coef(lnmq.model)[1:11]
  cc1 <- cc[3:11]
  denomboot <- 1-cc[2]
  splboot <-  exp( (cc[1] + (dfdiff %*% cc1)) * (1/denom) )
  boot <- cbind(boot,splboot)
}

## Get Eq Scale Standard Deviations
spl.sd <- apply(boot,1,sd)

spl.linminq.xall <- akmat %>%
  dplyr::select(ao,ko) %>%
  mutate(adults = as.integer(ao), kids = as.integer(ko)-1) %>%
  add_column(spl = as.integer(spl.base), 
             spl.sd = as.integer(spl.sd)) %>%
  dplyr::select(-c(ao,ko))

```


```{r lineary-spl-below, dependson="lcs-sub"}

base.data <- below.df
model <- lm(lnminq ~ lny + k1 + k2 + k3 + k4 + 
              a2 + a3 + a4 + a5 + a6 +  age + age.sq + hhh.male + 
              ethnic + province + settle + marital + education,
            data=base.data)

b <- coef(model)[1:11] # does not count non-income and non-adult/child vars.
b1 <- b[3:11]
denom <- 1-b[2]

spl.base <-  exp( (b[1] + (dfdiff %*% b1)) * (1/denom) )

### Bootstrapping - Not the cleanest, but works
boot <- NULL
for (i in 1:399){
  ss <- sample(dim(base.data)[1],replace=T)
  dd <- base.data[c(ss),]
  lnmq.model <- lm(lnminq ~ lny + k1 + k2 + k3 + k4 + 
                     a2 + a3 + a4 + a5 + a6 +  age + age.sq + hhh.male +
                     ethnic + province + settle + marital + education,
                   data=dd)
  cc <- coef(lnmq.model)[1:11]
  cc1 <- cc[3:11]
  denomboot <- 1-cc[2]
  splboot <-  exp( (cc[1] + (dfdiff %*% cc1)) * (1/denom) )
  boot <- cbind(boot,splboot)
}

## Get Eq Scale Standard Deviations
spl.sd <- apply(boot,1,sd)

spl.linminq.ybelow <- akmat %>%
  dplyr::select(ao,ko) %>%
  mutate(adults = as.integer(ao), kids = as.integer(ko)-1) %>%
  add_column(spl = as.integer(spl.base), 
             spl.sd = as.integer(spl.sd)) %>%
  dplyr::select(-c(ao,ko))

```


```{r linearx-spl-below, dependson="lcs-sub"}

base.data <- below.df
model <- lm(lnminq ~ lnx + k1 + k2 + k3 + k4 + 
              a2 + a3 + a4 + a5 + a6 +  age + age.sq + hhh.male + 
              ethnic + province + settle + marital + education,
            data=base.data)

b <- coef(model)[1:11] # does not count non-income and non-adult/child vars.
b1 <- b[3:11]
denom <- 1-b[2]

spl.base <-  exp( (b[1] + (dfdiff %*% b1)) * (1/denom) )

### Bootstrapping - Not the cleanest, but works
boot <- NULL
for (i in 1:399){
  ss <- sample(dim(base.data)[1],replace=T)
  dd <- base.data[c(ss),]
  lnmq.model <- lm(lnminq ~ lnx + k1 + k2 + k3 + k4 + 
                     a2 + a3 + a4 + a5 + a6 +  age + age.sq + hhh.male +
                     ethnic + province + settle + marital + education,
                   data=dd)
  cc <- coef(lnmq.model)[1:11]
  cc1 <- cc[3:11]
  denomboot <- 1-cc[2]
  splboot <-  exp( (cc[1] + (dfdiff %*% cc1)) * (1/denom) )
  boot <- cbind(boot,splboot)
}

## Get Eq Scale Standard Deviations
spl.sd <- apply(boot,1,sd)

spl.linminq.xbelow <- akmat %>%
  dplyr::select(ao,ko) %>%
  mutate(adults = as.integer(ao), kids = as.integer(ko)-1) %>%
  add_column(spl = as.integer(spl.base), 
             spl.sd = as.integer(spl.sd)) %>%
  dplyr::select(-c(ao,ko))

```



```{r lineary-spl-above, dependson="lcs-sub"}

base.data <- above.df
model <- lm(lnminq ~ lny + k1 + k2 + k3 + k4 + 
              a2 + a3 + a4 + a5 + a6 +  age + age.sq + hhh.male + 
              ethnic + province + settle + marital + education,
            data=base.data)

b <- coef(model)[1:11] # does not count non-income and non-adult/child vars.
b1 <- b[3:11]
denom <- 1-b[2]

spl.base <-  exp( (b[1] + (dfdiff %*% b1)) * (1/denom) )

### Bootstrapping - Not the cleanest, but works
boot <- NULL
for (i in 1:399){
  ss <- sample(dim(base.data)[1],replace=T)
  dd <- base.data[c(ss),]
  lnmq.model <- lm(lnminq ~ lny + k1 + k2 + k3 + k4 + 
                     a2 + a3 + a4 + a5 + a6 +  age + age.sq + hhh.male +
                     ethnic + province + settle + marital + education,
                   data=dd)
  cc <- coef(lnmq.model)[1:11]
  cc1 <- cc[3:11]
  denomboot <- 1-cc[2]
  splboot <-  exp( (cc[1] + (dfdiff %*% cc1)) * (1/denom) )
  boot <- cbind(boot,splboot)
}

## Get Eq Scale Standard Deviations
spl.sd <- apply(boot,1,sd)

spl.linminq.yabove <- akmat %>%
  dplyr::select(ao,ko) %>%
  mutate(adults = as.integer(ao), kids = as.integer(ko)-1) %>%
  add_column(spl = as.integer(spl.base), 
             spl.sd = as.integer(spl.sd)) %>%
  dplyr::select(-c(ao,ko))

```


```{r linearx-spl-above, dependson="lcs-sub"}

base.data <- above.df
model <- lm(lnminq ~ lnx + k1 + k2 + k3 + k4 + 
              a2 + a3 + a4 + a5 + a6 +  age + age.sq + hhh.male + 
              ethnic + province + settle + marital + education,
            data=base.data)

b <- coef(model)[1:11] # does not count non-income and non-adult/child vars.
b1 <- b[3:11]
denom <- 1-b[2]

spl.base <-  exp( (b[1] + (dfdiff %*% b1)) * (1/denom) )

### Bootstrapping - Not the cleanest, but works
boot <- NULL
for (i in 1:399){
  ss <- sample(dim(base.data)[1],replace=T)
  dd <- base.data[c(ss),]
  lnmq.model <- lm(lnminq ~ lnx + k1 + k2 + k3 + k4 + 
                     a2 + a3 + a4 + a5 + a6 +  age + age.sq + hhh.male +
                     ethnic + province + settle + marital + education,
                   data=dd)
  cc <- coef(lnmq.model)[1:11]
  cc1 <- cc[3:11]
  denomboot <- 1-cc[2]
  splboot <-  exp( (cc[1] + (dfdiff %*% cc1)) * (1/denom) )
  boot <- cbind(boot,splboot)
}

## Get Eq Scale Standard Deviations
spl.sd <- apply(boot,1,sd)

spl.linminq.xabove <- akmat %>%
  dplyr::select(ao,ko) %>%
  mutate(adults = as.integer(ao), kids = as.integer(ko)-1) %>%
  add_column(spl = as.integer(spl.base), 
             spl.sd = as.integer(spl.sd)) %>%
  dplyr::select(-c(ao,ko))

```


```{r spl-table, dependson="lineary-spl; lineary-spl-below; lineary-spl-above; linearx-spl; linearx-spl-below; linearx-spl-above; some-functions", results="asis", size = "footnotesize"}

spl0 <- estab(spl.linminq.yall) %>% rename(yall=results)
spl1 <- estab(spl.linminq.ybelow) %>% rename(ybelow=results)
spl2 <- estab(spl.linminq.yabove) %>% rename(yabove=results)
spl3 <- estab(spl.linminq.xall) %>% rename(xall=results)
spl4 <- estab(spl.linminq.xbelow) %>% rename(xbelow=results)
spl5 <- estab(spl.linminq.xabove) %>% rename(xabove=results)

spl.tab <- tibble(spl0,spl1[,3],spl2[,3],spl3[,3],spl4[,3],spl5[,3])


kable(spl.tab, format = "latex", align='rrrrrr',
      row.names = F,
      booktabs=TRUE, escape=FALSE, longtable=TRUE,
      linesep="",
      caption="Estimate of subjective poverty lines based on minimum household income, underpinned by linear regression model",
      col.names=c("Adults","Kids","All HH","Below","Above","All HH","Below","Above")) %>%
  add_header_above(c(" "=2, "Household Income"=3, "Household Expenditure" = 3)) %>%
  kable_styling(latex_options = c("striped", "hold_position", position="center")) %>%
  footnote(general = "Estimated poverty lines by household type (adults and kids), differentiated by whether we use all households, or those who report their income to be less than what is required. Bootstrapped standard errors (399 replications) are reported in paranethesis for each household type and regression control. Estimates underpinned by linear model of minimum income income required by the household against a range of controls including reported household (log) income or expenditure, household structure and location dummies.", escape=FALSE, general_title="",threeparttable=TRUE) 
```

# Quadratic parametric subjective poverty lines


```{r quady-spl, dependson="lcs-sub"}

base.data <- df.data
model <- lm(lnminq ~ lny + lny.sq + k1 + k2 + k3 + k4 + 
              a2 + a3 + a4 + a5 + a6 +  age + age.sq + hhh.male + 
              ethnic + province + settle + marital + education,
            data=base.data)

bcoef <- coef(model)[1:12] # does not count non-income and non-adult/child vars.
bcoef1 <- bcoef[4:12]

# This calculates for all household types at once... but no real roots?
c <- (bcoef[1] + (dfdiff %*% bcoef1))
b <- bcoef[2] - 1
a <- bcoef[3]

discriminant <- (b^2) - (4*a*c)

# How to choose?
root1 <- (-b + sqrt(discriminant))*(1/(2*a))
root2 <- (-b - sqrt(discriminant))*(1/(2*a))

spl.base <-  exp( root2 )

### Bootstrapping - Not the cleanest, but works
boot <- NULL
for (i in 1:399){
  ss <- sample(dim(base.data)[1],replace=T)
  dd <- base.data[c(ss),]
  lnmq.model <- lm(lnminq ~ lny + lny.sq + k1 + k2 + k3 + k4 + 
                     a2 + a3 + a4 + a5 + a6 +  age + age.sq + hhh.male +
                     ethnic + province + settle + marital + education,
                   data=dd)
  cc <- coef(lnmq.model)[1:12]
  cc1 <- cc[4:12]
  c <- (cc[1] + (dfdiff %*% cc1))
  b <- cc[2] - 1
  a <- cc[3]
  discriminant <- (b^2) - (4*a*c)
  root2 <- (-b - sqrt(discriminant))*(1/(2*a))
  splboot <-  exp( root2 )
  boot <- cbind(boot,splboot)
}

## Get Eq Scale Standard Deviations
spl.sd <- apply(boot,1,sd)

spl.qminq.yall <- akmat %>%
  dplyr::select(ao,ko) %>%
  mutate(adults = as.integer(ao), kids = as.integer(ko)-1) %>%
  add_column(spl = as.integer(spl.base), 
             spl.sd = as.integer(spl.sd)) %>%
  dplyr::select(-c(ao,ko))

```


```{r quadx-spl, dependson="lcs-sub"}

base.data <- df.data
model <- lm(lnminq ~ lnx + lnx.sq + k1 + k2 + k3 + k4 + 
              a2 + a3 + a4 + a5 + a6 +  age + age.sq + hhh.male + 
              ethnic + province + settle + marital + education,
            data=base.data)

bcoef <- coef(model)[1:12] # does not count non-income and non-adult/child vars.
bcoef1 <- bcoef[4:12]

# This calculates for all household types at once... but no real roots?
c <- (bcoef[1] + (dfdiff %*% bcoef1))
b <- bcoef[2] - 1
a <- bcoef[3]

discriminant <- (b^2) - (4*a*c)

# How to choose?
root1 <- (-b + sqrt(discriminant))*(1/(2*a))
root2 <- (-b - sqrt(discriminant))*(1/(2*a))

spl.base <-  exp( root2 )

### Bootstrapping - Not the cleanest, but works
boot <- NULL
for (i in 1:399){
  ss <- sample(dim(base.data)[1],replace=T)
  dd <- base.data[c(ss),]
  lnmq.model <- lm(lnminq ~ lnx + lnx.sq + k1 + k2 + k3 + k4 + 
                     a2 + a3 + a4 + a5 + a6 +  age + age.sq + hhh.male +
                     ethnic + province + settle + marital + education,
                   data=dd)
  cc <- coef(lnmq.model)[1:12]
  cc1 <- cc[4:12]
  c <- (cc[1] + (dfdiff %*% cc1))
  b <- cc[2] - 1
  a <- cc[3]
  discriminant <- (b^2) - (4*a*c)
  # How to choose?
  root2 <- (-b - sqrt(discriminant))*(1/(2*a))
  splboot <-  exp( root2 )
  boot <- cbind(boot,splboot)
}

## Get Eq Scale Standard Deviations
spl.sd <- apply(boot,1,sd)

spl.qminq.xall <- akmat %>%
  dplyr::select(ao,ko) %>%
  mutate(adults = as.integer(ao), kids = as.integer(ko)-1) %>%
  add_column(spl = as.integer(spl.base), 
             spl.sd = as.integer(spl.sd)) %>%
  dplyr::select(-c(ao,ko))

```


```{r spl-table-quad, dependson="quady-spl; quadx-spl; some-functions", results="asis", size = "footnotesize"}

spl0 <- estab(spl.qminq.yall) %>% rename(yall=results)
#spl1 <- estab(spl.linminq.ybelow) %>% rename(ybelow=results)
#spl2 <- estab(spl.linminq.yabove) %>% rename(yabove=results)
spl3 <- estab(spl.qminq.xall) %>% rename(xall=results)
#spl4 <- estab(spl.linminq.xbelow) %>% rename(xbelow=results)
#spl5 <- estab(spl.linminq.xabove) %>% rename(xabove=results)

spl.tab <- tibble(spl0,spl3[,3])


kable(spl.tab, format = "latex", align='rr',
      row.names = F,
      booktabs=TRUE, escape=FALSE, longtable=TRUE,
      linesep="",
      caption="Estimate of subjective poverty lines based on minimum household income, underpinned by linear regression model",
      col.names=c("Adults","Kids","All HH","All HH")) %>%
  add_header_above(c(" "=2, "Household Income"=1, "Household Expenditure" = 1)) %>%
  kable_styling(latex_options = c("striped", "hold_position", position="center")) %>%
  footnote(general = "Estimated poverty lines by household type (adults and kids), differentiated by whether we use all households, or those who report their income to be less than what is required. Bootstrapped standard errors (399 replications) are reported in paranethesis for each household type and regression control. Estimates underpinned by linear model of minimum income income required by the household against a range of controls including reported household (log) income or expenditure, household structure and location dummies.", escape=FALSE, general_title="",threeparttable=TRUE) 
```

# Smooth kids and adults


```{r lineary-spl-smooth, dependson="lcs-sub"}

base.data <- df.data %>%
  mutate(ao = as.numeric(ao),
         ko = as.numeric(ko))

model <- lm(lnminq ~ lny + ao + ko +  age + age.sq + hhh.male + 
              ethnic + province + settle + marital + education,
            data=base.data)

b <- coef(model)[1:4] # does not count non-income and non-adult/child vars.
b1 <- b[3:4]          # just the kids and adult bit
denom <- 1-b[2]

dfdiff <- akmat %>% dplyr::select(ao,ko) %>% 
  mutate(ao = as.numeric(ao),
         ko = as.numeric(ko)) %>%
  as.matrix()

spl.base <-  exp( (b[1] + (dfdiff %*% b1)) * (1/denom) )

### Bootstrapping - Not the cleanest, but works
boot <- NULL
for (i in 1:399){
  ss <- sample(dim(base.data)[1],replace=T)
  dd <- base.data[c(ss),]
  lnmq.model <- lm(lnminq ~ lny + ao + ko +  age + age.sq + hhh.male +
                     ethnic + province + settle + marital + education,
                   data=dd)
  cc <- coef(lnmq.model)[1:4]
  cc1 <- cc[3:4]
  denomboot <- 1-cc[2]
  splboot <-  exp( (cc[1] + (dfdiff %*% cc1)) * (1/denom) )
  boot <- cbind(boot,splboot)
}

## Get Eq Scale Standard Deviations
spl.sd <- apply(boot,1,sd)

spl.smoothminq.yall <- akmat %>%
  dplyr::select(ao,ko) %>%
  mutate(adults = as.integer(ao), kids = as.integer(ko)-1) %>%
  add_column(spl = as.integer(spl.base), 
             spl.sd = as.integer(spl.sd)) %>%
  dplyr::select(-c(ao,ko))

```


```{r linearx-spl-smooth, dependson="lcs-sub"}

base.data <- df.data %>%
  mutate(ao = as.numeric(ao),
         ko = as.numeric(ko))

model <- lm(lnminq ~ lnx + ao + ko +  age + age.sq + hhh.male + 
              ethnic + province + settle + marital + education,
            data=base.data)

b <- coef(model)[1:4] # does not count non-income and non-adult/child vars.
b1 <- b[3:4]          # just the kids and adult bit
denom <- 1-b[2]

dfdiff <- akmat %>% dplyr::select(ao,ko) %>% 
  mutate(ao = as.numeric(ao),
         ko = as.numeric(ko)) %>%
  as.matrix()

spl.base <-  exp( (b[1] + (dfdiff %*% b1)) * (1/denom) )

### Bootstrapping - Not the cleanest, but works
boot <- NULL
for (i in 1:399){
  ss <- sample(dim(base.data)[1],replace=T)
  dd <- base.data[c(ss),]
  lnmq.model <- lm(lnminq ~ lnx + ao + ko +  age + age.sq + hhh.male +
                     ethnic + province + settle + marital + education,
                   data=dd)
  cc <- coef(lnmq.model)[1:4]
  cc1 <- cc[3:4]
  denomboot <- 1-cc[2]
  splboot <-  exp( (cc[1] + (dfdiff %*% cc1)) * (1/denom) )
  boot <- cbind(boot,splboot)
}

## Get Eq Scale Standard Deviations
spl.sd <- apply(boot,1,sd)

spl.smoothminq.xall <- akmat %>%
  dplyr::select(ao,ko) %>%
  mutate(adults = as.integer(ao), kids = as.integer(ko)-1) %>%
  add_column(spl = as.integer(spl.base), 
             spl.sd = as.integer(spl.sd)) %>%
  dplyr::select(-c(ao,ko))

```


```{r quady-spl-smooth, dependson="lcs-sub"}

base.data <- df.data %>%
  mutate(ao = as.numeric(ao),
         ko = as.numeric(ko))

model <- lm(lnminq ~ lny + lny.sq + ao + ko +  age + age.sq + hhh.male + 
              ethnic + province + settle + marital + education,
            data=base.data)

b <- coef(model)[1:5] # does not count non-income and non-adult/child vars.
b1 <- b[4:5]          # just the kids and adult bit


dfdiff <- akmat %>% dplyr::select(ao,ko) %>% 
  mutate(ao = as.numeric(ao),
         ko = as.numeric(ko)) %>%
  as.matrix()

# This calculates for all household types at once... but no real roots?
c <- (b[1] + (dfdiff %*% b1))
bb <- b[2] - 1
a <- b[3]

discriminant <- (bb^2) - (4*a*c)

# How to choose?
root1 <- (-bb + sqrt(discriminant))*(1/(2*a))
root2 <- (-bb - sqrt(discriminant))*(1/(2*a))

# do not understand why not working?
spl.base <-  exp( root2 )


### Bootstrapping - Not the cleanest, but works
boot <- NULL
for (i in 1:399){
  ss <- sample(dim(base.data)[1],replace=T)
  dd <- base.data[c(ss),]
  lnmq.model <- lm(lnminq ~ lny + lny.sq + ao + ko +  age + age.sq + hhh.male +
                     ethnic + province + settle + marital + education,
                   data=dd)
  cc <- coef(lnmq.model)[1:5]
  cc1 <- cc[4:5]
  c <- (cc[1] + (dfdiff %*% cc1))
  bb <- cc[2] - 1
  a <- cc[3]
  #discriminant <- (bb^2) - (4*a*c)
  root2 <- (-bb - sqrt(discriminant))*(1/(2*a))
  splboot <-  exp( root2 )
  boot <- cbind(boot,splboot)
}

## Get Eq Scale Standard Deviations
spl.sd <- apply(boot,1,sd)

spl.smoothqminq.yall <- akmat %>%
  dplyr::select(ao,ko) %>%
  mutate(adults = as.integer(ao), kids = as.integer(ko)-1) %>%
  add_column(spl = as.integer(spl.base), 
             spl.sd = as.integer(spl.sd)) %>%
  dplyr::select(-c(ao,ko))

```


```{r quadx-spl-smooth, dependson="lcs-sub"}

base.data <- df.data %>%
  mutate(ao = as.numeric(ao),
         ko = as.numeric(ko))

model <- lm(lnminq ~ lnx + lnx.sq + ao + ko +  age + age.sq + hhh.male + 
              ethnic + province + settle + marital + education,
            data=base.data)

b <- coef(model)[1:5] # does not count non-income and non-adult/child vars.
b1 <- b[4:5]          # just the kids and adult bit


dfdiff <- akmat %>% dplyr::select(ao,ko) %>% 
  mutate(ao = as.numeric(ao),
         ko = as.numeric(ko)) %>%
  as.matrix()

# This calculates for all household types at once... but no real roots?
c <- (b[1] + (dfdiff %*% b1))
bb <- b[2] - 1
a <- b[3]

discriminant <- (bb^2) - (4*a*c)

# How to choose?
root1 <- (-bb + sqrt(discriminant))*(1/(2*a))
root2 <- (-bb - sqrt(discriminant))*(1/(2*a))

spl.base <-  exp( root2 )

### Bootstrapping - Not the cleanest, but works
boot <- NULL
for (i in 1:399){
  ss <- sample(dim(base.data)[1],replace=T)
  dd <- base.data[c(ss),]
  lnmq.model <- lm(lnminq ~ lnx + lnx.sq + ao + ko +  age + age.sq + hhh.male +
                     ethnic + province + settle + marital + education,
                   data=dd)
  cc <- coef(lnmq.model)[1:5]
  cc1 <- cc[4:5]
  c <- (cc[1] + (dfdiff %*% cc1))
  bb <- cc[2] - 1
  a <- cc[3]
  #discriminant <- (bb^2) - (4*a*c)
  root2 <- (-bb - sqrt(discriminant))*(1/(2*a))
  splboot <-  exp( root2 )
  boot <- cbind(boot,splboot)
}

## Get Eq Scale Standard Deviations
spl.sd <- apply(boot,1,sd)

spl.smoothqminq.xall <- akmat %>%
  dplyr::select(ao,ko) %>%
  mutate(adults = as.integer(ao), kids = as.integer(ko)-1) %>%
  add_column(spl = as.integer(spl.base), 
             spl.sd = as.integer(spl.sd)) %>%
  dplyr::select(-c(ao,ko))

```


```{r spl-table-smooth, dependson="lineary-spl-smooth; linearx-spl-smooth; quadx-spl-smooth; quady-spl-smooth; some-functions", results="asis", size = "footnotesize"}

spl0 <- estab(spl.smoothminq.yall) %>% rename(yall=results)
spl1 <- estab(spl.smoothqminq.yall) %>% rename(yquad=results)
#spl2 <- estab(spl.linminq.yabove) %>% rename(yabove=results)
spl3 <- estab(spl.smoothminq.xall) %>% rename(xall=results)
spl4 <- estab(spl.smoothqminq.xall) %>% rename(xquad=results)
#spl5 <- estab(spl.linminq.xabove) %>% rename(xabove=results)

spl.tab <- tibble(spl0,spl1[,3],spl3[,3],spl4[,3])


kable(spl.tab, format = "latex", align='rrrr',
      row.names = F,
      booktabs=TRUE, escape=FALSE, longtable=TRUE,
      linesep="",
      caption="Estimate of subjective poverty lines based on minimum household income, underpinned by linear regression model",
      col.names=c("Adults","Kids","Linear","Quadratic","Linear","Quadratic")) %>%
  add_header_above(c(" "=2, "Household Income"=2, "Household Expenditure" = 2)) %>%
  kable_styling(latex_options = c("striped", "hold_position", position="center")) %>%
  footnote(general = "Estimated poverty lines by household type (adults and kids), differentiated by whether we use all households, or those who report their income to be less than what is required. Bootstrapped standard errors (399 replications) are reported in paranethesis for each household type and regression control. Estimates underpinned by linear model of minimum income income required by the household against a range of controls including reported household (log) income or expenditure, household structure and location dummies.", escape=FALSE, general_title="",threeparttable=TRUE) 
```


\newpage
\singlespacing
# References {-}