---
title: "Required minimum income and subjective poverty lines"
subtitle: "Estimates and comparisons from 2014 to 2023"
author: 
  - "Steven F. Koch^[Corresponding author: Department of Economics, University of Pretoria, Private Bag X20, Hatfield, South Africa; +27-12-420-5285; steve.koch@up.ac.za]"
  - "Bernice Macquela^[Department of Economics, University of Pretoria]"
thanks: We would like to thank participants in the applied microeconomics seminar at the same university for their comments and suggestions. Some of the preliminary work for this project is incorporated in Bernice's Master's research at the University of Pretoria [@Macquela2024Thesis]. 
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  bookdown::pdf_document2: 
    latex_engine: xelatex
    dev: tikz
    keep_tex: true
    number_sections: true
    toc: false
  bookdown::gitbook: null
booktabs: yes
bibliography: 
    - refs.bib
    - bernice-refs.bib
header-includes:
    - \usepackage{setspace}\doublespacing
#    - \usepackage{draftwatermark}
    - \usepackage{dcolumn}
    - \usepackage{subfig}
    - \usepackage{threeparttablex}
    - \usepackage{longtable}
abstract: \singlespacing This research uses minimum income questions to estimate subjective poverty lines and examine subjective poverty rates, relative to objective poverty rates in South Africa. Comparisons of these lines and rates are undertaken over the period 2014 to 2023, based on two different nationally representative surveys. We find that subjective poverty lines per adult and child increased between 2014 and 2023. We also find per capita subjective values in-line with South Africa's upper bound money-metric poverty line in 2023, but not for 2014. Furthermore, if the 2014 estimates are adjusted to account for inflation, they would be larger than both the subjective povery lines estimated for 2023 in many cases. Despite some similarities, we also find that the subjective/objective poverty rates do not coincide for any year or any household type, suggesting more work is needed to develop a poverty line that is consistent by household type at any point in time, and preferably, over time.
---

<!--
    - \usepackage{draftwatermark}
\SetWatermarkText{Draft}
\AddToShipoutPictureFG{
  \AtPageCenter{% or \AtTextCenter
    \makebox[0pt]{\rotatebox[origin=c]{45}{%
      \scalebox{5}{\texttransparent{0.3}{Draft}}%
    }}
  }
}
-->

<!-- subject: JEL Classifications I15, J21
thanks: The authors would like to thank someone. 
csl: empirical-economics.csl 
-->

```{r global_options, include=FALSE, cache=FALSE}
knitr::opts_chunk$set(cache=TRUE,
                      echo=FALSE,
                      autodep=TRUE,
                      message=FALSE,
                      warning=FALSE,
                      #dev='tikz',
                      dev='png',
                      out.width='80%',
                      out.height='35%',
                      fig.align='center')

def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
  x <- def.chunk.hook(x, options)
  ifelse(options$size != "normalsize", paste0("\\", options$size,"\n\n", x, "\n\n \\normalsize"), x)
})

knitr::opts_knit$set(kable.force.latex = TRUE)

library(tidyverse)
library(haven)
library(lubridate)
library(kableExtra)
library(np)  
library(quantreg)
library(nnet)
library(AER)
library(ivreg)
library(sandwich)
library(REndo)
library(qwraps2)
  options(qwraps2_markup = "latex")
library(stargazer)
library(MASS)
library(broom)
library(purrr)

par(family = 'mono')

options(scipen = 999,
        np.messages=FALSE)

set.seed(42)
num.boot <- 1499 
num.splits <- 5000
q1 <- 0.025
q2 <- 0.975
nmulti <- 20

### Working Directory
#setwd('/Volumes/GoogleDrive/My Drive/Inequality/EqScalesFood')
```

```{r some-functions}
### Some useful functions ###

CM <- function(cm) {
  factor.values.eval <- colnames(cm)
  CM <- matrix(0,nrow(cm),nrow(cm))
  rownames(CM) <- rownames(cm)
  colnames(CM) <- rownames(cm)
  for(i in 1:ncol(cm)) CM[,(1:nrow(cm))[rownames(cm)==factor.values.eval[i]]] <- cm[,i]
  return(list(CM=CM,CCR=sum(diag(CM))/sum(CM)))
}

## this is a bit silly, but is driven by the difference in names between 
## prediction and model... Could also change the model data naming...
CM.logit <- function(cm) {
  factor.values.eval <- rownames(cm)
  CM <- matrix(0,nrow(cm),nrow(cm))
  rownames(CM) <- rownames(cm)
  colnames(CM) <- rownames(cm)
  for(i in 1:ncol(cm)) CM[,(1:nrow(cm))[rownames(cm)==factor.values.eval[i]]] <- cm[,i]
  return(list(CM=CM,CCR=sum(diag(CM))/sum(CM)))
}

stars <- function(x){
  case_when(x >=0 & x <= 0.005 ~ "$^a$", 
            x >=0 & x <= 0.01 ~ "$^b$",
            x >=0 & x <= 0.05 ~ "$^c$",
            x >=0 & x <= 0.1 ~ "$^d$",
            x>0.1 ~ "")
}

ctab <- function(sm, cluster = NULL) {
  # If cluster variable is provided, use cluster-robust SEs
  if (!is.null(cluster)) {
    Vcov <- vcovCL(sm, cluster = cluster)
  } else {
    Vcov <- vcovHC(sm, type = "HC1") # default robust SE
  }
  
  mm <- summary(sm, vcov = Vcov)
  modsum <- mm$coefficients
  
  n <- rownames(modsum)
  ses <- paste0("(", formatC(modsum[,2], format="f", digits=3, drop0trailing = FALSE), ")")
  z <- stars(modsum[,4])
  betas <- paste0(formatC(modsum[,1], format="f", digits=4, drop0trailing = FALSE), z)
  
  t1 <- tibble(n=n, b=betas, s=ses) %>%
    pivot_longer(!n, names_to="params", values_to="results")
  
  return(t1)
}

nlstab <- function(sm){
  modsum <- sm$parameters
  n <- rownames(modsum)
  CIs <- paste0("(",format(modsum[,1]-1.96*modsum[,2],digits=1,nsmall=2)," -- ",
                format(modsum[,1]+1.96*modsum[,2],digits=1,nsmall=2), ")")
  betas <- format(modsum[,1],digits=1,nsmall=4)
  t1 <- tibble(n=n,b=betas,s=CIs) %>%
    pivot_longer(!n,names_to="params",values_to = "results")
}

ivctab <- function(sm){
  mm <- summary(sm)
  modsum <- mm$coefficients
  n <- rownames(modsum)
  ses <- paste0("(",formatC(modsum[,2],format="f",digits=3, drop0trailing = F),")")
  z <- stars(modsum[,4])
  betas <- paste0(formatC(modsum[,1],format="f",digits=4, drop0trailing = F),z)
  t1 <- tibble(n=n,b=betas,s=ses) %>%
    pivot_longer(!n,names_to="params",values_to = "results")
  modnost <- sm$diagnostics
  nn <- rownames(modnost)
  degfree1 <- as.character(modnost[,1])
  z1 <- stars(modnost[,4])
  ivstat <- paste0(formatC(modnost[,3],format="f",digits=3, drop0trailing = F),z1)
  t2 <- tibble(n=nn,params=degfree1,results=ivstat)
  t <- rbind(t1,t2)
}

sptab <- function(sm){
  modsum <- sm
  n <- rownames(modsum)
  colnames(sm) <- c("betas","ses")
  tt <- sm[,1]/sm[,2]
  pp <- 2*pnorm(-abs(tt))
  n <- rownames(modsum)
  ses <- paste0("(",format(modsum[,2],digits=1,nsmall=3),")")
  z <- stars(pp)
  betas <- paste0(format(modsum[,1],digits=1,nsmall=4),z)
  t1 <- tibble(n=n,b=betas,s=ses) %>%
    pivot_longer(!n,names_to="params",values_to = "results")
}

estab <- function(sm){
  sm.all <- sm
  sm <- as.matrix(sm)
  n <- paste0(sm[,1]," ",sm[,2])
  ses <- paste0("(",formatC(as.numeric(sm[,4]),format="f",digits=0, drop0trailing = F),")")
  #z <- stars(sm[,4]) - not the right function, and not going to include.
  sm3.form <- formatC(as.numeric(sm[,3]),format="f",digits=0)
  #betas <- paste0(sm3.form,z)
  t1 <- tibble(n=n, b=sm3.form,s=ses) %>%
    pivot_longer(!n,names_to="result-type",values_to = "results") %>%
    separate(n, into =c("adults","kids"))
  estab.out <- t1[,c(1,2,4)]
}

only_perc <- function(x,
                   digits = getOption("qwraps2_frmt_digits", 2),
                   na_rm = FALSE,
                   show_denom = "ifNA",
                   show_symbol = TRUE,
                   markup = "latex") #getOption("qwraps2_markup", "latex")) 
                   {
  d <- sum(!is.na(x))
  n <- sum(x, na.rm = na_rm)
  p <- frmt(100*n/d, digits)

  if (show_denom == "never") {
    rtn <- paste0(p,"%")
  } else {
    if (show_denom =="always" | any(is.na(x))) {
      rtn <- paste0(frmt(as.integer(n)), "/", frmt(as.integer(d)), " (", p, "%)")
    } else {
      rtn <- paste0(p,"%")
    }
  }

  if (!show_symbol) {
    rtn <- gsub("%", "", rtn)
  }


  if (markup == "latex") {
    rtn <- gsub("%", "\\\\%", rtn)
  }

  return(rtn)
}

quadRoots <- function(a, b, c) {

print(paste0("You have chosen the quadratic equation ", a, "x^2 + ", b, "x + ", c, "."))

discriminant <- (b^2) - (4*a*c)

  if(discriminant < 0) {  # if discriminant is less than zero i.e no real roots
    return(paste0("This quadratic equation has no real numbered roots."))
  }
  else if(discriminant > 0) { # If discriminant is greater than 0 ie real roots
    x_int_plus <- (-b + sqrt(discriminant)) / (2*a)
    x_int_neg <- (-b - sqrt(discriminant)) / (2*a)

    return(paste0("The two x-intercepts for the quadratic equation are ",
                  format(round(x_int_plus, 5), nsmall = 5), " and ",
                  format(round(x_int_neg, 5), nsmall = 5), "."))
  }
  else #discriminant = 0  i.e only one root 
    x_int <- (-b) / (2*a)
    return(paste0("The quadratic equation has only one root. This root is ",
                  x_int))
}
```


```{r lcs}

# LCS data
person <- read_dta(file = "../lcsdata/lcs-2014-2015-persons-final-v1.dta")
household <- read_dta(file = "../lcsdata/lcs-2014-2015-households-v1.dta")

# hhsize, number of kids (age < 17) in each household to match ghs data
# Could probably pull this from household file, but already have the code
person1 <- person %>%
  dplyr::select(UQNO, Q14AGE, Q11710GRANTS) %>%
  group_by(UQNO) %>%
  summarise(hhsize = n(), # household size by appearance times of each ID
            kids = sum(Q14AGE <= 17), # number of child (age<17)
            adults = hhsize - kids,
            grants = sum(Q11710GRANTS == 1)
  ) %>%
  mutate(UQNO = as.character(UQNO))

person2 <- person %>%
  dplyr::select(UQNO, PERSONNO, Q12SEX, Q13POPGROUP, Q14AGE, Q17MARITAL, Q21HIGHLEVEL, 
         province_code, SETTLEMENT_TYPE) %>%
  filter(PERSONNO==1, 
         Q17MARITAL != 9,
         Q21HIGHLEVEL != 31,
         Q21HIGHLEVEL != 32,
         Q21HIGHLEVEL != 99) %>%  
  transmute(UQNO = as.character(UQNO),
            age = Q14AGE,
            hhh.dummy = ifelse(Q12SEX==1,1,0),
            hhh.male = as_factor(Q12SEX),
            ethnic = as_factor(Q13POPGROUP),
            province = as_factor(province_code),
            settle = factor(SETTLEMENT_TYPE, levels = c(1,2,4,5),
                            labels=c("Urban Formal","Urban Informal",
                                     "Traditional Area","Rural Formal")),
            marital = as_factor(Q17MARITAL),
            education = factor(Q21HIGHLEVEL, 
                               levels = c(98,1:25,27,28:29,26,30),
                               labels=c("none",rep("nqf0",9),"nqf1","nqf2",
                                        "nqf3",rep("nqf4",2),
                                       "nqf1","nqf2","nqf3",
                                       rep("nqf5",3), rep("nqf4",2),"nqf5",
                                       "nqf6",rep("nqf7",2),
                                       rep("nqf8",2),rep("nqf9-10",2))),
            Q21HIGHLEVEL) %>%
  droplevels() 

# household level variables
house.df <- household %>%
  dplyr::select(
    UQNO, income_inkind, expenditure_inkind, SURVEYDATE, Q229NETINCOME, 
    Q6105IMAGINE, Q116PRESENT, hholds_wgt, Q221AFOOD, Q221BHOUSING,
    Q221CCLOTHING, Q221DHEALTH) %>%
  filter(Q6105IMAGINE != 9, Q116PRESENT != 9, 
         Q221AFOOD != 9, Q221BHOUSING != 9,
         Q221CCLOTHING != 9,
         Q221DHEALTH != 9) %>% ## loses 790 obs.. before health
  transmute(
    UQNO = as.character(UQNO),
    psu = substr(UQNO,1,11),
    wt = hholds_wgt,
    surveydate = dmy(SURVEYDATE), # I just want to have separate months and years..
    month = as.factor(surveydate),
    #month = month(surveydate),
    surveyyear = year(surveydate),
    x = as.numeric(expenditure_inkind), 
    # the value of expenditures including in kind expenditure incurred by 
    # households for 12 months inflated/deflated to April 2015 using CPI
    x.month = x/12, #Monthly total expenditure
    y = as.numeric(income_inkind),  
    # 63 observations have 0 values... length(which(house.df$y==0))
    # also deflated/inflated to April 2015
    y.month = y/12,
    y2.month = y.month^2,
    lnx = log(x.month),
    lny = log(y.month),
    minq = Q229NETINCOME, 
    # 466 zero values (after dropping the 493 above) ... length(which(house.df$minq == 0))
    lnminq = log(minq),
  ) %>%
  filter(is.finite(lny),
         is.finite(lnx),
         is.finite(lnminq)) %>%  # Not sure this affects the final lcs data, though
  mutate(enough_inc = as.factor(lny >= lnminq)) %>%
  droplevels()
  


#merge above dataframes to get a dataframe LCS2014
lcs2014 <- person1 %>%
  full_join(person2, by="UQNO") %>%
  full_join(house.df, by="UQNO") %>%
  drop_na() %>%
  filter(adults > 0,
         adults <= 6,
         kids <= 4) %>%
  mutate(ao = ordered(adults),
         ko = ordered(kids),
         k0 = 1*(kids==0),
         k1 = 1*(kids==1),
         k2 = 1*(kids==2),
         k3 = 1*(kids==3),
         k4 = 1*(kids==4),
         a1 = 1*(adults==1),
         a2 = 1*(adults==2),
         a3 = 1*(adults==3),
         a4 = 1*(adults==4),
         a5 = 1*(adults==5),
         a6 = 1*(adults==6),
         lnx.sq = lnx^2,
         lny.sq = lny^2,
         age.sq = age^2) 
  #dplyr::select(-c(x.month,y.month,minq,Q21HIGHLEVEL,
  #                 surveydate, wt, hhh.dummy))

## It appears that we lose 312 observations for missing values, 
## we lose 556 in total; the extra coming from limiting adults and kids in hh
  
# save image
save(lcs2014, file = "../lcsdata/lcs2014-v2.Rdata")

# save a single data frame: LCS2014
# This gets used by the NP files.
#save(LCS2014, file="../lcsdata/LCS2014df.Rdata")

rm(person, household, house.df, person1, person2)

## Some parameters
LCSn <- nrow(lcs2014)
n2 <- 24
n1 <- LCSn-n2


```


```{r lcs-sub, dependson="lcs"}

# kids limited to max 4 and adults to max 6
dfref <- cbind(k1 = 0, k2 = 0, k3 = 0, k4 = 0, 
               a2 = 0, a3 = 0, a4 = 0, a5 = 0, a6 = 0)

akmat <- lcs2014 %>%
  dplyr::select(adults,kids,
                a1, a2, a3, a4, a5, a6, 
                k0, k1, k2, k3, k4) %>%
  unique() %>%
  arrange(kids) %>%
  group_by(kids) %>%
  arrange(adults) %>%
  ungroup()

dfalt <- akmat %>%
  dplyr::select(k1,k2,k3,k4,
                a2,a3,a4,a5,a6) 

dfdiff <- data.matrix(sweep(dfalt,2,dfref)) 
```


```{r ghs}

household <- read_dta(file = "../ghs2023/ghs-2023-hhold-v1.dta") 
person <- read_dta(file = "../ghs2023/ghs-2023-person-v1.dta") 

ghs.house <- household %>%
  dplyr::select(uqnr, psu, prov, totmhinc, fin_reqinc, 
                fin_compinc, fin_exp, hholdsz, chld17yr_hh, 
                metro_code, soc_grant_hh, rotation) %>%
  filter(totmhinc != 9999999,
         fin_reqinc != 9999999,
         totmhinc > 0,
         fin_exp !=14) %>%
  transmute(uqnr = as.character(uqnr),
            psu=psu,
            lny = log(totmhinc),
            y.month = totmhinc,
            y2.month = y.month^2,
            lny.sq = lny^2,
            lnminq = log(fin_reqinc),
            minq = fin_reqinc,
            x = as_factor(fin_exp),
            hhsize = hholdsz,
            kids = chld17yr_hh,
            adults = hhsize - kids,
            # This is province and metro combined, 
            # But, I will keep it..
            province = as_factor(prov),
            metro_code = as_factor(metro_code),
            month = as_factor(rotation),
            grants = soc_grant_hh,
            enough_inc = as.factor(as.numeric(fin_compinc <= 3))) %>%
  droplevels()


ghs.person <- person %>%
  dplyr::select(uqnr, personnr, Sex, Population, age, 
                hhc_marital, education, geotype) %>%
  filter(as.numeric(personnr)==1, 
         hhc_marital != 9,
         education != 28,
         education != 29,
         education != 99) %>%  
  transmute(uqnr = as.character(uqnr),
            age = age,
            hhh.male = as_factor(Sex),
            ethnic = as_factor(Population),
            marital = as_factor(hhc_marital),
            settle = factor(geotype, levels = c(1,2,3),
                            labels = c("Urban","Traditional","Farms")),
            education = factor(education, 
                               levels = c(98,0:27),
                               labels=c("none",rep("nqf0",9),"nqf1","nqf2",
                                        "nqf3","nqf4", "nqf1","nqf2","nqf3",
                                       rep("nqf5",3), rep("nqf4",2),"nqf5",
                                       "nqf6", rep("nqf7",2), "nqf8", 
                                       "nqf9", "nqf10"))) %>%
  droplevels() 

ghs2023 <- ghs.house %>%
  full_join(ghs.person, by="uqnr") %>%
  drop_na() %>%
  # could make the number of adults and kids bigger?
  filter(adults > 0, # there are 39 kid-headed households using my definition
         adults <= 6,
         kids <= 4) %>%
  mutate(ao = ordered(adults),
         ko = ordered(kids),
         k0 = 1*(kids==0),
         k1 = 1*(kids==1),
         k2 = 1*(kids==2),
         k3 = 1*(kids==3),
         k4 = 1*(kids==4),
         a1 = 1*(adults==1),
         a2 = 1*(adults==2),
         a3 = 1*(adults==3),
         a4 = 1*(adults==4),
         a5 = 1*(adults==5),
         a6 = 1*(adults==6),
         lny.sq = lny^2,
         age.sq = age^2)  

rm(household, person, ghs.person, ghs.house)

save(ghs2023, file = "../ghs2023/ghs2023-v2.Rdata")
```


\newpage
\pagenumbering{arabic}

# Introduction

The measurement of poverty and inequality is a point of focus for economists and policymakers, especially those based in countries like South Africa, where poverty rates are high and income disparities are stark [@leibbrandtetal2012]. In determining poverty rates, the method employed by Statistics South Africa is money-metric, where they set three primary thresholds: an upper-bound, lower-bound and food poverty line [@StatsSA2021PovertyLines]. @budlenderetal2015 suggest an upper bound that is about 25% higher than the one used by Statistics South Africa at the time [@StatsSA2015PovertyLines]. These poverty lines are constructed using the cost-of-basic-needs approach [@r98], which links welfare to the consumption of goods and services. 

However, @Seekings07 and @MethDias04, for example, argue that poverty measures based on income and expenditure ignore the non-income components of living standards. Others argue that money-metric measures ignore fluctuations related to differences in household size and other factors within a household [@poseletal2020; @RavallionLokshin01; @zwane18]. Additionally, money-metric measures may inaccurately assess the degree of poverty, if the income/expenditures used do not align with appropriate aspects of living standards [@poselrogan2016]. Intuitively, individual or household differences in characteristics  are likely to affect needs, e.g., household size and composition, regional cost of living, and subjective perceptions are plausibly different [@Daleyetal20]. @megbowan18 offers some discussion of regional variation within the Eastern Cape, although the focus was not on potential economies of scale that might arise at the level of the household.

An alternative is to employ a subjective income poverty approach, underpinned by the “happiness and economics” literature [@Ravallion14; @Ferreretal03]. This approach might use responses to a minimum income question (MIQ), or similar, assessing individuals’ perceptions of the minimum required (net) income for an acceptable standard of living [@Goedhartetal1977]. Minimum income questions may highlight disparities that objective measures miss [@RavallionLokshin01]. Furthermore, answers to such questions can be dissected across a range of additional factors -- family type, size and geographic location -- that might relate to responses [@bdmnpwz17; @wzbzy20]. The ability to control for additional correlates deepens our understanding of the roles and robustness of various determinants of poverty; it can also help us detect policy focal points [@do13]. 

Although research into subjective well-being is common in South Africa, the estimation of monetary subjective poverty lines is less so. Possibly, subjective poverty lines are not commonly estimated, due to  a range of complications/criticisms. A list of which certainly includes reference effects [@borahetal2019] or other endogeneities related to actual income and/or household formation. Additional concerns relate to the meaning of "income" [@pradhanravallion2000; @Lokshin2006Madagascar] or other cognitive issues associated with hypothetical situations. See, for example, @bradbury1989, @melenbergvansoest1996 and @steigeretalproceedings.

@budlenderetal2015 offer a different reason, suggesting that the extraction of a monetary measure of a subjective poverty line is difficult in such analyses. Certainly, it is not obvious how one might extract a single line (per household type) from the Socially Perceived Necessities (SPN) Approach; see @Wright2008IPSEProfile for the initial South African application. This work suggests 31 or 32 necessities -- 36 if there are children in the household -- that there is broad agreement across population groups, and that, as incomes increase, households lack fewer necessities. However, @Wright2008IPSEProfile do not attempt to place a monetary value on the SPNs. @Wright_Padley_Zembe-Mkabile_2020 provide a brief discussion of a follow-up pilot relating to the earlier work, but I am not aware of any further progress on that front.

In order to develop monetary values, it is necessary to incorporate measures of income or expenditure, possibly based on a broader survey. @Noble2015DecentLivingLevel correlate the SPNs available in the 2008/09 South African Living Conditions Survey with income (monthly per capita and per employed adult). Unfortunately, most surveys do not contain all SPNs, as they have not been designed to do so. Their results offer a range of incomes, presented as either mean or median (the latter to avoid outliers) incomes for households that hold a particular number of SPNs. For example, for households with 21 SPNs, average equivalised earnings (average earnings, so does not include grant income, per adult in the household) is R2 750. The per capita median is approximately R1000 per month. However, the per capita measure ignores potential economies of scale, while the wide range of SPNs and incomes raise difficulties in deriving a monetary equivalent.

@Frye2018DSLIndex extend the analysis to the 2014/15 LCS, adjusting for inflation. Their SPNs are underscored by the initial focus group research outlined in @Wright2008IPSEProfile and their subjective poverty lines continue to be SPN-dependent. For 21 SPNs, median per capita household income was approximately R7000 per month. Most recently, @Frye2023DecentStandard offers some comparison between the 2014/15 data and the 2022 Census, which does not capture income in as much detail. For the same 21 SPNs, they find an average of R4 500 per month per capita, a value that is lower than that estimated for 2015. Because of size of the estimated reduction, they also inflation-adjusted the 2015 values, which yielded an average of approximately R8 300 for 21 SPNs. Similar concerns related to per capita and the extent of potential poverty lines remain; thus, the need to further formalise a subjective poverty line remains.

In a related literature, @posel2014 considers individual subjective well-being, while @poselrogan2016 focus on the household. Each of these analyses are founded on ladder-type questions (where respondents rank their living conditions as being representative of very poor to wealthy or they rate their satisfaction with life from very dissatisfied to very satisfied). @Frye2014DecentLiving and @poselrogan2019, as far as we know, are the only ones to use MIQ in their analysis. @poselrogan2019 focus on income aspirations, i.e., the level of income households aspired to reach. They further examine how reported minimum income correlates with a range of household characteristics, including objective/subjective measures of economic standing and their district's local economic conditions. @Frye2014DecentLiving considers a few subjective measures from the 2008/09 South African Living Conditions Survey, including one based on MIQ; however, she does not outline how those monetary values are derived. 

Although it may not be obvious how one would extract one poverty line from the wide range of SPNs, the literature is quite clear on how to extract such lines from MIQ questions. In this research, we estimate subjective poverty lines, based upon MIQ, comparing their implied impact on poverty, relative to money-metric lines that are available. We do so across two surveys from South Africa undertaken approximately 10 years apart [@lcs2014; @ghs2023], to see whether there have been any changes in subjective views of poverty over that time period, how much the subjective measures differ from the objective measures, and what those differences imply for poverty rates for different types of households. Our subjective poverty lines are estimated by ordinary linear and quantile regressions that indirectly determine the intersection between actual and required income. That intersection underscores the subjective poverty line; see @Goedhartetal1977 or @ravallion2014poor for details.  We also explore potential endogeneities following standard IV methods as well as heteroskedastic IV methods [@Lewbel2012], due to the fact that instrument options are limited, at best.

Despite the extensive body of South African poverty research in South Africa, we are not aware of any estimates of subjective poverty lines based on the MIQ or some other subjective measure of well-being. We further examine how it has changed over time. Given that we are able to control for extensive household heterogeneity, we estimate the cost of an additional child and the cost of an additional adult, which we find is not the same. Neither are those estimates similar to the per capita values outlined by Statistics South Africa. Thus, poverty rates by household type differ substantially (in-sample) when comparing money-metric and subjective poverty lines. We also find large increases in the additional cost per child and adult in the 2023 survey compared to the 2014/15 survey, which implies that subjective poverty rates in 2023 are relatively higher than those in 2014/15, when compared to the upper bound poverty lines.

# Literature

The minimum income question has a long history and association with poverty, dating back at least to @VANPRAAG1971, although the question has changed since then. @Goedhartetal1977 argue that responses to MIQ are positively correlated with own income and family size; therefore, poverty lines should be appropriately adjusted.  @LanjouwRavallion1995 and @v02, amongst others, uncover similar correlations between MIQ responses, income and household size.  

@kkw88 demonstrate that MIQ can be utilized to evaluate subjective poverty, stressing its ability to capture perceived income adequacy. Similarly, @fv91 argue that subjective data can help understand poverty dynamics across heterogeneous populations, while @rojas2007 finds some non-poor money-metric households to be subjectively impoverished, partly due to differences in household composition and regional cost variations. Thus, it is likely to capture different features of poverty than those that arise from money-metric measures. MIQ may reflect aspirations, rather than needs [@kv78; @RavallionLokshin01, @s83]. Thus, combining subjective poverty with money-metric data may provide a better composite measure of poverty than subjective measures alone [@poselrogan2016].

We are not aware of any research on subjective poverty in South Africa underscored by MIQ. @roberts2025wp uses MIQ to assess the cost of an additional household member, while @poselrogan2019 use MIQ to examine income aspirations. Thus, we offer one of the first analyses of subjective poverty, based on the MIQ in South Africa. However, other subjective measures of economic status do feature. @MollerSaris2001 and @Neff2007SWB focus on life satisfaction. On the other hand, @bd04, @poselrogan2016, as well as @repecbila, use subjective poverty -- respondents label themselves as poor, just getting by, or rich, depending on the exact phrasing of the question -- which is categorical. Other categorical measures include multi-step ladders, upon which households place themselves -- on the bottom, top rung, or somewhere in between -- relative to others; @BlaauwPretorius2013, @repecbila and @Kirsten2023 make use of these. For the most part, these analyses examine the determinants of subjective poverty, often comparing substrata of the population to each other finding, amongst others, that black South Africans are subjectively poorer than other population groups. 

In related literature, the MIQ underscores equivalence scales [@bishopetal2014; @mysikova2022], which enable comparisons across different types of households [@deaton1997book; @f04; @dudel2021assessing; @koch2022; @koch2023]. Allowing for subjectivity recognizes that poverty lines may relate to individual or household perceptions of an acceptable standard of living in any given society [@r92]. Comparability requires assumptions related to utility, such as base independence [@lewbel1989] or equivalence scale exactness [@blackorbydonaldson1993], which are rarely supported empirically [@pendakur1999]. Given these limitations, @blundelllewbel1991 and @blackorbydonaldson1993 suggest focusing attention on minimum utility, where individuals make ends meet. Duality, with respect to utility, implies a minimum level of income corresponding to the minimum level of utility, which underscores 'local comparability' [@grodneretal2022]. 

Local comparability represents a formalization of the intersection approach [@Goedhartetal1977]; the intersection occurs where individuals’ perceptions of their minimum income needs aligns with their actual income. In several studies, the MIQ is used to estimate the income needed for a household of a specific composition to reach what they consider an acceptable quality of living [@bishopetal2014; @mysikova2022]. Although both @bishopetal2014 and @mysikova2022 examine MIQ, they focus on equivalence scales, rather than subjective poverty lines. Equivalence scales are determined by the ratio of one household's expenditure relative to a reference expenditure; intuitively, poverty lines could be inferred from their research. In both cases [@bishopetal2014; @mysikova2022], equivalence scales exhibit greater economies of scale than objective scales; thus, the underlying (subjective) poverty lines would have a rather small household size gradient. 

In South Africa, the equivalence scale literature is fairly recent [@yatchewsunderi2003; @poseletal2016; @poseletal2020; @koch2022]. Although @poseletal2016 consider hypothetical scales, the others estimate (semi-)parametric models of food shares (and other consumption good shares), which, via the Engel method can be converted into equivalence scales [@deaton1997book]. @koch2023 estimates subjective equivalence scales, underpinned by consumption adequacy [@pradhanravallion2000]. As with the subjective literature elsewhere, Koch's subjective scales exhibit extensive economies of scale, suggesting that subjective poverty lines are relatively inelastic with respect to household size. Below, we examine that gradient in greater detail, using South African survey data from 2014/15 and 2023. 


# Data

We make use of data from two sources.^[All data and code to recreate all results, included in the text or not, as well as all figures and tables is available from the author, upon request.] The first is the 2014-2015 Living Conditions Survey (LCS), which was collected by Statistics South Africa [@lcs2014]. The second is the 2023 General Household Survey (GHS), collected by the same [@ghs2023]. The 2014/15 survey offers a baseline; it was used in previous research into both objective and subjective equivalence scales [@koch2022; @koch2023]. The 2023 GHS results are presented partly for comparison and partly for purposes of an update. More recent data might yield different results and conclusions.

Each survey contains data regarding households and the individuals contained therein, although not necessarily in the exact same format. Importantly, each contains the MIQ, as well as information on household structure (number of household members and their ages - we focus our attention on those in the household at least four nights per week), household income per month, location, the marital status, sex, population group and education level of the household head, and survey participation timing. In particular, we separate the number of children from the number of adults using 18 years of age as the threshold. As previously noted, our variable of interest is the response to MIQ; it is the minimum amount of net income (per month) required for the household to get by. To remove outliers in the analysis, we trim the top and bottom 5% of MIQ. We discuss reasons for that decision in the results section.

The data files were combined for each survey to compile the preceding information.^[Data wrangling was undertaken in `R` [@rcore], making use primarily of the `tidyverse` [@tidyverse] package and `haven` [@haven].] For both data sets, individuals/households with missing information for the relevant data were removed. The LCS initially contained 23 380 households, while the analysis sub-sample is based on 18 699.^[We removed households with more than 4 children and more than 6 adults. We also removed households that did not offer answers to MIQ or answered 0, and other subjective welfare questions. Furthermore, for some of the household heads, education and marital status were not available. We also removed the top and bottom 5% of observations.] The GHS initially included 20 927 households, while our analysis sample was reduced to 16 975 after removing missing information and trimming.^[As with the LCS, we removed missing information on MIQ (as well as reported 0 values) education and marital status. We also removed households that did not provide information on either income or minimum income required, as well as the top and bottom 5% of observations.]


# Methods

We apply standard linear and quantile regression analysis. We also apply instrumental variable methods to address some endogeneity concerns.

## Regression

Standard methods assume a parametric relationship between reported minimum income $(\underline{Y})$, actual income $(Y)$, household demographic characteristics $(D)$ and other characteristics related to household decisions, such as location, household head marital status and other controls $(Z)$, and unobserved components $u$. We assume linearity in income and treat the number of adults $(A)$ and children $(K)$ as continuous, which yields expression \eqref{eq:continuous}.
\begin{equation}
\label{eq:continuous}
 \underline{Y} = \alpha + \beta Y + \phi A + \theta K + \sum_j \zeta_j Z_j + u
\end{equation} 
We focus our attention on this model because (i) it yields per adult and per child estimates, and (ii) the outcome is measured in rands, such that the underlying estimates are in rand per child or adult. The estimates, once adjusted for the intersection method, are then easy to compare to the upper and lower bound money-metric poverty lines. We also note that we do not inflation-adjust the data, before undertaking regression, since each regression is performed for each year, and much of the analysis is per year. When comparing estimated poverty lines, however, we will adjust as necessary.

We also consider extensions to this relationship. For example, we consider a quadratic income relationship, as in \eqref{eq:quad}. 
\begin{equation}
\label{eq:quad}
 \underline{Y} = \alpha + \beta  Y + \gamma  Y^2 + \phi A + \theta K + \sum_j \zeta_j Z_j + u
\end{equation}
Furthermore, since the preceding expressions assume that each additional adult and/or child increases the minimum income at the same rate, we extend the analysis as suggested by @koch2022 and @koch2023. Specifically, we create a dummy variable representation of household structure, as in \eqref{eq:linindex}. Specifically, we define $a_{a} = \mathbf{1}(A=a)$, with the kids $(\kappa)$ dummy variables similarly defined. An extension with a quadratic relationship in actual income is also estimated.
\begin{equation}
\label{eq:linindex}
\underline{Y} = \alpha + \beta Y + \sum_a \delta_a a_{a} + \sum_k \psi_k \kappa_{k} + \sum_j \zeta_j Z_j + u 
\end{equation}
Finally, we estimate a quantile regression, based on \eqref{eq:continuous}. 

The subjective poverty lines arising from this analysis are determined by the regression estimates, identification of which is founded on exogeneity. In other words, household structure and income are not correlated with unobserved information, conditional on the controls included in the model - a strong assumption. Amongst other issues, previous literature has suggested that: household size depends on the gender of the household head [@poseletal2016]; household arrangements depend on migration [@wittenberg2017decomposing] and access to income, and by implication, the source of that income [@hamoudithomas2014]; that income could also be measured with error [@burgerersawp]. Furthermore, the economics/demography literature is replete with models suggesting that fertility is endogenous, and, therefore, so is the number of (biological) children in the household [@tshiswaka2017contraceptive]. 

Addressing these potential threats to identification is problematic. Identification would be assured, if appropriate confounders can be included in the analysis or, if such confounders are not observable, instruments are available. Our analysis includes income, as well as a numerical count of grant recipients in the household to capture income and variation in income source. The latter is likely strongly correlated with household structure, as well as minimum income required (thus, it should not be used as an instrument). To deal with measurement error in income, one could follow control function or heteroskedasticity instrumentation methods [@Lewbel2012]. The method outlined by @dong2010 and applied by koch2022, requires a continuous variable with a greater range than the endogenous regressor. For the LCS data, expenditure meets this expectation; however, for the GHS data, expenditure is only available across 12 categories -- it is not continuous and certainly does not cover a wider range than reported income. Thus, we instrument via heteroskedasticity, but do not report the full set of estimates, to address endogeneity concerns; we also use expenditure as an instrument for income in some specifications.^[Full results are available upon request. The effect of the endogeneity control is discussed in the manuscript.] 

## Subjective poverty lines

Subjective poverty lines are defined by fixed points [@Goedhartetal1977], where $\underline{Y} = f(\underline{Y}, D, Z)$. Under linearity, that fixed point occurs at the intercept, adjusted for the regression slope; it also differs depending on whether we assume constant requirements for children and adults, or if we allow for a quadratic income relationship.^[With a quadratic term in the regression, the fixed point is determined by the solution to the quadratic formula -- we did not uncover any complex roots in our analysis.] Treating adults and kids as continuous variables, as in \eqref{eq:continuous}, the subjective poverty line is defined by \eqref{eq:linear-spl}, where the derivatives with respect to adults, children and any other control are fixed by the model parameters. 
\begin{equation}
\label{eq:linear-spl}
\underline{Y} =  \frac{\alpha + \phi A + \theta K + \sum_j \zeta_j Z_j }{1-\beta}
\end{equation}

In other words, estimates yield a constant adjustment factor; the change in required income for an additional adult is $\phi/(1-\beta)$, while the change per child is $\theta/(1-\beta)$.^[The partial derivative of $\underline{Y}$ with respect to $A$ in \eqref{eq:linear-spl} is constant $(\phi)$. In models where squared income is included, the underlying calculations are more complicated because the quadratic formula is used to determine the poverty line. In other words, $\underline{Y} = (2a)^{-1}\times (-b \pm \sqrt{b^2 - 4ac})$, where $a=\gamma$, $b=1-\beta$ and $c= \alpha + \phi A + \theta K$, ignoring any additional $Z_j$. There are two roots; one yields required income levels approximately five times its mean value in the two surveys, while the other yields levels relatively close to the mean values in the surveys; we choose the smaller of these, because it is more representative of the data.] As reported below, we find support for this modelling assumption, and, therefore, we do not derive poverty lines underpinned by non-constant changes per child that would be implied by estimates from \eqref{eq:linindex} or \eqref{eq:quad}. For the quantile models, equation \eqref{eq:linear-spl} remains relevant; however, because estimates are quantile-dependent, so are the resulting poverty lines.

Two important constraints are implied by equation \eqref{eq:linear-spl}. The first is that income proportionality cannot be or exceed one, as that would lead to either undefined or negative poverty lines. The second is similar, in that the intercept plus the child and adult components cannot be negative, as that would imply a negative, and, therefore, unrealistic, poverty line. Below, we find that for the GHS data, negative poverty lines could arise, if the data was not trimmed, due to negative intercepts. Thus, the majority of this research is underpinned by trimmed (top and bottom 5%) data.


# Initial results

We begin by describing the data and providing estimates based on the linear and quadratic regressions outlined in the methods section.

## Descriptive statistics

Descriptive statistics are available in the appendix; see Tables \@ref(tab:dstat) and \@ref(tab:dstat-ghs). The data is presented for the entirety of the estimation sample of households, and is further separated by an indicator of whether the household's minimum required income is larger than its actual income, i.e., they have enough (or too little). The data suggests a slight increase (over time) in the proportion of households with too little, an increase in the level of education of the household head, as well as increases in both income and reported minimum required income. According to the data, minimum required income increased by approximately R3 000, from R7 200 to R 10 500 (45.8%), while actual income increased by about R1 000 (14.1%). During that same time period, recorded inflation was between 3.3% and 6.9%. Over 9 years, and compounding, average prices increased 54% during the time period.^[The inflation calculation covers the beginning of 2015 to the end of 2023, which slightly over-represents by a few months, the full time frame between surveys.] In other words, the data suggests that households were finding it harder to "get by" in 2023, than in 2014/15. We formalise this further, below.

## Regression results

The main regression results are also presented in the appendix. See Tables \@ref(tab:smooth-table) and \@ref(tab:dummies-table) for the OLS results.^[Full quantile and IV estimates are available from the authors upon request. We illustrate the main quantile estimates, below, and we offer a brief discussion of the main IV results, as well. As might be expected, the quantile results suggest higher minimum incomes are required from those in better economic circumstances. The endogeneity corrections, on the other hand, yield more nuanced results.] The regression results offer numerous insights. We find that required minimum income is increasing in actual income, which is often observed in the literature, starting with @Goedhartetal1977; we refer to this estimate as income proportionality, because it represents the conditional requirement "pass-through" from actual income to required minimum income. We also find that required minimum incomes are increasing in both the number of adults and children. Relatively speaking, the adult estimate is 50% (or more) larger than the child estimate in 2014, but is fairly similar in 2023. Thus, compared to adults, children are associated with a relatively larger increase in the required minimum in 2023. Although not directly comparable, child costs inferred from subjective measures of adequacy are also rather large in the local equivalence scale literature [@koch2023]. We also find large differences across population groups, in line with  post-apartheid expectations [@poselrogan2019]. 

We find a negative relationship, of similar magnitude across years, of the number of grants in the households: the reduction is approximately R750 to R1 000 per grant. To put this into perspective, the old-age pension was R1 860 -- R1 880 in 2015 and R2 090 -- R2 110 in 2023, depending on the age of the recipient. Other grants were smaller, such as the child support grant (R330 in 2015 to R500 in 2022) and the social relief of distress grant (non-existent in 2015 to R350 in 2023). Although out of the scope of this research, and worth further investigation, the grant pass-through to minimum income requirements appears to be less than the average value of the grants, implying significant economies of scale with respect to grant-income pooling, and, by implication, household structure. 

```{r model-formulas}

ysmooth <- formula(minq ~ y.month + adults + kids +  age + age.sq +
                    hhh.male + ethnic + province + settle +
                    marital + education + month + grants)

sdummy <- formula(minq ~ y.month + k1 + k2 + k3 + k4 + 
                    a2 + a3 + a4 + a5 + a6 +  age + age.sq +
                    hhh.male + ethnic + province + settle +
                    marital + education + month + grants)

quad <- formula(minq ~ y.month + y2.month + adults + kids +  
                  age + age.sq +hhh.male + ethnic + province + 
                  settle + marital + education + month + grants)

qdummy <- formula(minq ~ y.month + y2.month + k1 + k2 + k3 + k4 + 
                    a2 + a3 + a4 + a5 + a6 +  age + age.sq +
                    hhh.male + ethnic + province + settle +
                    marital + education + month + grants)

```

```{r linear-models, dependson="lcs; model-formulas"}

## dummy rows for squared term..
ddr1 <- tibble(n="lny.sq",results = NA)
ddr2 <- tibble(n="lny.sq",results = NA)
ddr <- rbind(ddr1, ddr2)

base.data <- lcs2014 %>%
  filter(minq <= quantile(minq, 0.95, na.rm = TRUE),
         minq >= quantile(minq, 0.05, na.rm = TRUE))

lineary_smooth <- lm(ysmooth,
                     data=base.data)
lineary_smooth_tab <- ctab(lineary_smooth, 
                           cluster = base.data$psu)[1:8,c(1,3)]
lysmooth_tab <- rbind(lineary_smooth_tab[1:4,],
                      ddr,
                      lineary_smooth_tab[5:8,])

lcs_ly_smooth_tab <- ctab(lineary_smooth, 
                           cluster = base.data$psu)

lineary_dummies <- lm(sdummy,
                     data=base.data)
lineary_dummies_tab <- ctab(lineary_dummies, 
                           cluster = base.data$psu)[1:22,3]
lydum_tab <- rbind(lineary_dummies_tab[1:4,],
                     ddr[,2],
                     lineary_dummies_tab[5:22,])
lcs_ly_dummies_tab <- ctab(lineary_dummies, 
                           cluster = base.data$psu)

quadraticy_smooth <- lm(quad,
                       data=base.data)
quadraticy_smooth_tab <- ctab(quadraticy_smooth, 
                           cluster = base.data$psu)[1:10,3] 
lcs_qy_smooth_tab <- ctab(quadraticy_smooth, 
                           cluster = base.data$psu)

quadraticy_dummies <- lm(qdummy,
                         data=base.data)
quadraticy_dummies_tab <- ctab(quadraticy_dummies, 
                           cluster = base.data$psu)[1:24,3]
lcs_qy_dummies_tab <- ctab(quadraticy_dummies, 
                           cluster = base.data$psu)

# hypothesis tests...
vcov_cluster_ldum <- vcovCL(lineary_dummies, cluster = ~ psu)
vcov_cluster_qdum <- vcovCL(quadraticy_dummies, cluster = ~ psu)

# Joint test of coefficients k1..k4 and a2..a6
kids_ldum <- linearHypothesis(lineary_dummies,
                 c("4*k1 = k4", 
                   "3*k1 = k3",
                   "2*k1 = k2"),
                 vcov = vcov_cluster_ldum,
                 test = "F")

kids_qdum <- linearHypothesis(quadraticy_dummies,
                 c("4*k1 = k4", 
                   "3*k1 = k3",
                   "2*k1 = k2"),
                 vcov = vcov_cluster_qdum,
                 test = "F")

adults_ldum <- linearHypothesis(lineary_dummies,
                 c("3*a2 = a6",
                   "2.5*a2 = a5",
                   "2*a2 = a4", 
                   "1.5*a2 = a3"),
                 vcov = vcov_cluster_ldum,
                 test = "F")

adults_qdum <- linearHypothesis(quadraticy_dummies,
                 c("3*a2 = a6",
                   "2.5*a2 = a5",
                   "2*a2 = a4", 
                   "1.5*a2 = a3"),
                 vcov = vcov_cluster_qdum,
                 test = "F")

all_ldum <- linearHypothesis(lineary_dummies,
                 c("4*k1 = k4", 
                   "3*k1 = k3",
                   "2*k1 = k2",
                   "3*a2 = a6",
                   "2.5*a2 = a5",
                   "2*a2 = a4", 
                   "1.5*a2 = a3"),
                 vcov = vcov_cluster_ldum,
                 test = "F")

all_qdum <- linearHypothesis(quadraticy_dummies,
                 c("4*k1 = k4", 
                   "3*k1 = k3",
                   "2*k1 = k2",
                   "3*a2 = a6",
                   "2.5*a2 = a5",
                   "2*a2 = a4", 
                   "1.5*a2 = a3"),
                 vcov = vcov_cluster_qdum,
                 test = "F")


```

```{r linear-models-ghs, dependson="ghs;model-formulas"}
## dummy rows for squared term..
ddr1 <- tibble(n="y2.month",results = NA)
ddr2 <- tibble(n="y2.month",results = NA)
ddr <- rbind(ddr1, ddr2)

base.data <- ghs2023 %>%
  filter(minq <= quantile(minq, 0.95, na.rm = TRUE),
         minq >= quantile(minq, 0.05, na.rm = TRUE))

lineary_smooth <- lm(ysmooth,
                     data=base.data)
lineary_smooth_ghs <- ctab(lineary_smooth, 
                           cluster = base.data$psu)[1:8,c(1,3)]
lysmooth_ghs <- rbind(lineary_smooth_ghs[1:4,],
                      ddr,
                      lineary_smooth_ghs[5:8,])
ghs_ly_smooth_tab <- ctab(lineary_smooth, 
                           cluster = base.data$psu)

lineary_dummies <- lm(sdummy,
                      data=base.data)
lineary_dummies_ghs <- ctab(lineary_dummies, 
                           cluster = base.data$psu)[1:22,3]
lydum_ghs <- rbind(lineary_dummies_ghs[1:4,],
                   ddr[,2],
                   lineary_dummies_ghs[5:22,])
ghs_ly_dummies_tab <- ctab(lineary_dummies, 
                           cluster = base.data$psu)

quadraticy_smooth <- lm(quad,
                        data=base.data)
quadraticy_smooth_ghs <- ctab(quadraticy_smooth, 
                           cluster = base.data$psu)[1:10,3] 
ghs_qy_smooth_tab <- ctab(quadraticy_smooth, 
                           cluster = base.data$psu)

quadraticy_dummies <- lm(qdummy,
                         data=base.data)
quadraticy_dummies_ghs <- ctab(quadraticy_dummies, 
                           cluster = base.data$psu)[1:24,3]
ghs_qy_dummies_tab <- ctab(quadraticy_dummies, 
                           cluster = base.data$psu)

# hypothesis tests...
vcov_cluster_ldum <- vcovCL(lineary_dummies, cluster = ~ psu)
vcov_cluster_qdum <- vcovCL(quadraticy_dummies, cluster = ~ psu)

# Joint test of coefficients k1..k4 and a2..a6
kids_ldum_ghs <- linearHypothesis(lineary_dummies,
                 c("4*k1 = k4", 
                   "3*k1 = k3",
                   "2*k1 = k2"),
                 vcov = vcov_cluster_ldum,
                 test = "F")

kids_qdum_ghs <- linearHypothesis(quadraticy_dummies,
                 c("4*k1 = k4", 
                   "3*k1 = k3",
                   "2*k1 = k2"),
                 vcov = vcov_cluster_qdum,
                 test = "F")

adults_ldum_ghs <- linearHypothesis(lineary_dummies,
                 c("3*a2 = a6",
                   "2.5*a2 = a5",
                   "2*a2 = a4", 
                   "1.5*a2 = a3"),
                 vcov = vcov_cluster_ldum,
                 test = "F")

adults_qdum_ghs <- linearHypothesis(quadraticy_dummies,
                 c("3*a2 = a6",
                   "2.5*a2 = a5",
                   "2*a2 = a4", 
                   "1.5*a2 = a3"),
                 vcov = vcov_cluster_qdum,
                 test = "F")


all_ldum <- linearHypothesis(lineary_dummies,
                 c("4*k1 = k4", 
                   "3*k1 = k3",
                   "2*k1 = k2",
                   "3*a2 = a6",
                   "2.5*a2 = a5",
                   "2*a2 = a4", 
                   "1.5*a2 = a3"),
                 vcov = vcov_cluster_ldum,
                 test = "F")

all_qdum <- linearHypothesis(quadraticy_dummies,
                 c("4*k1 = k4", 
                   "3*k1 = k3",
                   "2*k1 = k2",
                   "3*a2 = a6",
                   "2.5*a2 = a5",
                   "2*a2 = a4", 
                   "1.5*a2 = a3"),
                 vcov = vcov_cluster_qdum,
                 test = "F")
```

```{r basemodel, dependson="lcs;ghs"}
lcs_data <- lcs2014 %>%
  filter(y.month <= quantile(y.month, 0.95, na.rm = TRUE),
         y.month >= quantile(y.month, 0.05, na.rm = TRUE)) %>%
  zap_labels()

ghs_data <- ghs2023 %>%
  filter(y.month <= quantile(y.month, 0.95, na.rm = TRUE),
         y.month >= quantile(y.month, 0.05, na.rm = TRUE)) %>%
  zap_labels()


lcs_model <- lm(ysmooth,
                data=lcs_data)

ghs_model <- lm(ysmooth,
                data=ghs_data)


lcs_kids <- coef(lcs_model)["kids"]
ghs_kids <- coef(ghs_model)["kids"]

lcs_adults <- coef(lcs_model)["adults"]
ghs_adults <- coef(ghs_model)["adults"]

lcs_inc <- coef(lcs_model)["y.month"]
ghs_inc <- coef(ghs_model)["y.month"]
```

Finally, we find that constant (per child, per adult) coefficients are not an entirely unreasonable approximation across both surveys.^[We test this with a joint hypothesis test accounting for data clustering. For all models in both years, the constant hypothesis is not rejected for adults. We find that in adults are responsible for rejecting the null hypothesis, when it is. Technically, test is whether (for example) the estimate for four children is four times that of one child, the estimate for four adults is two times the estimate for two adults, and so on. Although the null hypothesis is rejected in some of the joint tests, it is not rejected in all, and, therefore, we are comfortable continuing our focus on a per adult/child basis. All tests were corrected to account for potential clustering. Analysis was undertaken using the `sandwich` package [@sandwich1; @sandwich2] and `car` package [@car] in R. Some manipulation of results was based on the `broom` package [@broom].] For that reason, we will focus our attention on subjective poverty lines underscored by constant per adult and per child models, i.e, linear models.


# Sensitivity analysis

For sensitivity analysis, we focused our attention on two main issues. The first relates to location and scale that offers implications for potential heteroskedasticity. Thus, we estimated equation \eqref{eq:continuous} across a range of quantiles of the data.^[Quantile regressions were estimated via the `quantreg` package [@quantreg], which was cluster bootstrapped for correct standard errors; the bootstrapped data was organised via the `purrr` package [@purrr].]  The second relates to potential endogeneity, which we address via standard and heteroskedasticity IV corrections [@Lewbel2012].^[These models make use of the `AER` package [@AER] and `REndo` package [@REndo] from R.] 

## Quantile regression


```{r lcs-exog-quantiles, dependson="model-formulas;lcs"}

taus <- seq(0.05,0.95,0.05)
Rboot <- 500

lcs_data <- lcs2014 %>%
  zap_labels()

# Estimate quantile regressions for each tau
# smooth adults/kids
# bootstrap for clusters, but I am not sure I want to do it

lcs_tidy_fit <- map_dfr(taus, function(tau) {
  fit <- rq(ysmooth, data = lcs_data, tau = tau)
  # summary with clustered bootstrap SEs
  s <- summary(fit, se = "boot", cluster = lcs_data$psu, R = Rboot)
  # s$coefficients should be a matrix/data.frame: rows = terms, cols ~ (est, se, t, p)
  coef_df <- as.data.frame(s$coefficients)
  # normalize column names (different quantreg versions use different colnames)
  cn <- colnames(coef_df)
  if (length(cn) >= 4) names(coef_df)[1:4] <- c("estimate", "std.error", "statistic", "p.value")
  coef_df$term <- rownames(coef_df)
  coef_df %>%
    dplyr::select(term, estimate, std.error, statistic, p.value) %>%
    mutate(tau = tau) %>%
    # ensure consistent types
    mutate(estimate = as.numeric(estimate), 
           std.error = as.numeric(std.error))
})
  


```


```{r ghs-exog-quantiles, dependson="model-formulas;ghs"}

taus <- seq(0.05,0.95,0.05)
Rboot <- 500

ghs_data <- ghs2023 %>%
  zap_labels

# Estimate quantile regressions for each tau
# smooth adults/kids
# bootstrap for clusters, but I am not sure I want to do it

ghs_tidy_fit <- map_dfr(taus, function(tau) {
  fit <- rq(ysmooth, data = ghs_data, tau = tau)
  # summary with clustered bootstrap SEs
  s <- summary(fit, se = "boot", cluster = ghs_data$psu, R = Rboot)
  # s$coefficients should be a matrix/data.frame: rows = terms, cols ~ (est, se, t, p)
  coef_df <- as.data.frame(s$coefficients)
  # normalize column names (different quantreg versions use different colnames)
  cn <- colnames(coef_df)
  if (length(cn) >= 4) names(coef_df)[1:4] <- c("estimate", "std.error", "statistic", "p.value")
  coef_df$term <- rownames(coef_df)
  coef_df %>%
    dplyr::select(term, estimate, std.error, statistic, p.value) %>%
    mutate(tau = tau) %>%
    # ensure consistent types
    mutate(estimate = as.numeric(estimate), 
           std.error = as.numeric(std.error))
})

```

In a follow-up to the standard regressions, we estimated a series of quantile models to capture both location and scale effects in the data; the data was not trimmed for the quantile models, because quantile regressions are robust to the presence of potential outliers that might affect ordinary linear regression coefficients [@Angrist2009MHE]. Such a model inherently captures non-linearities in the data, possibly arising from heteroskedasticity. In Figures \@ref(fig:exog-plots-kids) to \@ref(fig:exog-plots-intercept), we illustrate the regression parameters for children, adults, income and the intercept respectively; we include the cluster-bootstrapped 95% confidence interval around those estimates in each figure. We also illustrate the mean estimate, which arises from the uncorrected ordinary least squares regression on the trimmed data. Each figure contains two panels, one for the Living Conditions Survey data; the other for the General Household Survey data.

```{r exog-plots-kids, dependson="lcs-exog-quantiles; ghs-exog-quantiles;basemodel", fig.cap = "Children quantile plots", fig.subcap = c("Living Conditions Survey","General Household Survey"), out.width=c("48%","48%")}

# lcs
lcs_tidy_fit %>%
  filter(term == "kids") %>%
  mutate(
    conf.low = estimate - 1.96 * std.error,
    conf.high = estimate + 1.96 * std.error
  ) %>%
ggplot(aes(x = tau, y = estimate)) +
  geom_ribbon(aes(ymin = conf.low, ymax = conf.high), 
              fill = "skyblue", alpha = 0.4) +
  geom_line(color = "blue", linewidth = 1.2) +
  geom_hline(yintercept = lcs_kids, color = "red", 
             linetype = "dashed") +
  labs(
    title = "Quantile Regression Coefficients with 95% CI",
    x = "Quantile (tau)", 
    y = "Child estimate"
  ) +
  theme_minimal(base_size = 12)

#plot_drinker <- 
ghs_tidy_fit %>%
  filter(term == "kids") %>%
  mutate(
    conf.low = estimate - 1.96 * std.error,
    conf.high = estimate + 1.96 * std.error
  ) %>%
ggplot(aes(x = tau, y = estimate)) +
  geom_ribbon(aes(ymin = conf.low, ymax = conf.high), 
              fill = "skyblue", alpha = 0.4) +
  geom_line(color = "blue", linewidth = 1.2) +
  geom_hline(yintercept = ghs_kids, color = "red", 
             linetype = "dashed") +
  labs(
    title = "Quantile Regression Coefficients with 95% CI",
    x = "Quantile (tau)", 
    y = "Child estimate"
  ) +
  theme_minimal(base_size = 12)


```

As can be inferred from the figures, there are non-linearities in the underlying relationship between required minimum income, the number of children, the number of adults, actual household income and the intercept term -- each of these is important for computing a subjective poverty line. Furthermore, the nonlinear relationship is not constant over time.

```{r exog-plots-adults, dependson="lcs-exog-quantiles; ghs-exog-quantiles;basemodel", fig.cap = "Adult quantile plots", fig.subcap = c("Living Conditions Survey","General Household Survey"), out.width=c("48%","48%")}

# lcs
lcs_tidy_fit %>%
  filter(term == "adults") %>%
  mutate(
    conf.low = estimate - 1.96 * std.error,
    conf.high = estimate + 1.96 * std.error
  ) %>%
ggplot(aes(x = tau, y = estimate)) +
  geom_ribbon(aes(ymin = conf.low, ymax = conf.high), 
              fill = "skyblue", alpha = 0.4) +
  geom_line(color = "blue", linewidth = 1.2) +
  geom_hline(yintercept = lcs_adults, color = "red", 
             linetype = "dashed") +
  labs(
    title = "Quantile Regression Coefficients with 95% CI",
    x = "Quantile (tau)", 
    y = "Adult estimate"
  ) +
  theme_minimal(base_size = 12)

#plot_drinker <- 
ghs_tidy_fit %>%
  filter(term == "adults") %>%
  mutate(
    conf.low = estimate - 1.96 * std.error,
    conf.high = estimate + 1.96 * std.error
  ) %>%
ggplot(aes(x = tau, y = estimate)) +
  geom_ribbon(aes(ymin = conf.low, ymax = conf.high), 
              fill = "skyblue", alpha = 0.4) +
  geom_line(color = "blue", linewidth = 1.2) +
  geom_hline(yintercept = ghs_adults, color = "red", 
             linetype = "dashed") +
  labs(
    title = "Quantile Regression Coefficients with 95% CI",
    x = "Quantile (tau)", 
    y = "Adult estimate"
  ) +
  theme_minimal(base_size = 12)


```

For children, see Figure \@ref(fig:exog-plots-kids), the quantile gradient is bumpy for the LCS data, although generally positive and mostly increasing. For the GHS data the gradient follows a smoother upward-sloped path. Furthermore, the GHS child estimates are larger at all quantiles than the LCS estimates. A somewhat similar pattern is observed for the adult-quantile gradient, Figure \@ref(fig:exog-plots-adults). It follows an increasing "trend", while the LCS estimates are lower than the GHS estimates across all quantiles. 

```{r exog-plots-income, dependson="lcs-exog-quantiles; ghs-exog-quantiles;basemodel", fig.cap = "Income quantile plots", fig.subcap = c("Living Conditions Survey","General Household Survey"), out.width=c("48%","48%")}

# lcs
lcs_tidy_fit %>%
  filter(term == "y.month") %>%
  mutate(
    conf.low = estimate - 1.96 * std.error,
    conf.high = estimate + 1.96 * std.error
  ) %>%
ggplot(aes(x = tau, y = estimate)) +
  geom_ribbon(aes(ymin = conf.low, ymax = conf.high), 
              fill = "skyblue", alpha = 0.4) +
  geom_line(color = "blue", linewidth = 1.2) +
  geom_hline(yintercept = lcs_inc, color = "red", 
             linetype = "dashed") +
  labs(
    title = "Quantile Regression Coefficients with 95% CI",
    x = "Quantile (tau)", 
    y = "Income estimate"
  ) +
  theme_minimal(base_size = 12)

#plot_drinker <- 
ghs_tidy_fit %>%
  filter(term == "y.month") %>%
  mutate(
    conf.low = estimate - 1.96 * std.error,
    conf.high = estimate + 1.96 * std.error
  ) %>%
ggplot(aes(x = tau, y = estimate)) +
  geom_ribbon(aes(ymin = conf.low, ymax = conf.high), 
              fill = "skyblue", alpha = 0.4) +
  geom_line(color = "blue", linewidth = 1.2) +
  geom_hline(yintercept = ghs_inc, color = "red", 
             linetype = "dashed") +
  labs(
    title = "Quantile Regression Coefficients with 95% CI",
    x = "Quantile (tau)", 
    y = "Income estimate"
  ) +
  theme_minimal(base_size = 12)


```

With respect to income, we continue to see increasing estimates across the quantiles for both the LCS and the GHS, Figure \@ref(fig:exog-plots-income). Furthermore, the estimates are fairly similar across the quantiles, although the GHS estimates are slightly larger for nearly all quantiles. Finally, the intercept-quantile plots -- Figure \@ref(fig:exog-plots-intercept) -- are rather different over the two surveys: it is positive and increasing for the LCS data, but only positive for some quantiles and decreasing over many of the quantiles in 2023, yielding a negative intercept for a wide range of quantiles. However, the dashed line plots the regression coefficient arising after the bottom and top 5% have been trimmed; that coefficient is positive, also shown in Tables \@ref(tab:smooth-table) and \@ref(tab:dummies-table). Thus, trimming is necessary for the resulting poverty lines to be plausible, as it insures positive intercepts..

```{r basemodel-intercept, dependson="lcs;ghs"}
lcs_data <- lcs2014 %>%
  filter(minq <= quantile(minq, 0.95, na.rm = TRUE),
         minq >= quantile(minq, 0.05, na.rm = TRUE)) %>%
  zap_labels()

ghs_data <- ghs2023 %>%
  filter(minq <= quantile(minq, 0.95, na.rm = TRUE),
         minq >= quantile(minq, 0.05, na.rm = TRUE)) %>%
  zap_labels()


lcs_model <- lm(ysmooth,
                data=lcs_data)

ghs_model <- lm(ysmooth,
                data=ghs_data)


lcs_int <- coef(lcs_model)["(Intercept)"]
ghs_int <- coef(ghs_model)["(Intercept)"]

```


```{r exog-plots-intercept, dependson="lcs-exog-quantiles; ghs-exog-quantiles;basemodel-intercept", fig.cap = "Intercept quantile plots", fig.subcap = c("Living Conditions Survey","General Household Survey"), out.width=c("48%","48%")}

# lcs
lcs_tidy_fit %>%
  filter(term == "(Intercept)") %>%
  mutate(
    conf.low = estimate - 1.96 * std.error,
    conf.high = estimate + 1.96 * std.error
  ) %>%
ggplot(aes(x = tau, y = estimate)) +
  geom_ribbon(aes(ymin = conf.low, ymax = conf.high), 
              fill = "skyblue", alpha = 0.4) +
  geom_line(color = "blue", linewidth = 1.2) +
   geom_hline(yintercept = lcs_int, color = "red", 
              linetype = "dashed") +
  labs(
    title = "Quantile Regression Coefficients with 95% CI",
    x = "Quantile (tau)", 
    y = "Intercept estimate"
  ) +
  theme_minimal(base_size = 12)

#plot_drinker <- 
ghs_tidy_fit %>%
  filter(term == "(Intercept)") %>%
  mutate(
    conf.low = estimate - 1.96 * std.error,
    conf.high = estimate + 1.96 * std.error
  ) %>%
ggplot(aes(x = tau, y = estimate)) +
  geom_ribbon(aes(ymin = conf.low, ymax = conf.high), 
              fill = "skyblue", alpha = 0.4) +
   geom_line(color = "blue", linewidth = 1.2) +
  geom_hline(yintercept = ghs_int, color = "red", 
              linetype = "dashed") +
  labs(
    title = "Quantile Regression Coefficients with 95% CI",
    x = "Quantile (tau)", 
    y = "Intercept estimate"
  ) +
  theme_minimal(base_size = 12)


```

```{r quant-tab, dependson="lcs-exog-quantiles;ghs-exog-quantiles", results="asis"}

coef_subset <- lcs_tidy_fit %>%
  filter(term %in% c("adults","kids","y.month"),
         tau %in% c("0.15","0.3","0.45","0.6","0.75")) %>%
  dplyr::select(tau,term,estimate) %>%
  pivot_wider(
    names_from = term,
    values_from = estimate
  )

lcs_change <- coef_subset %>%
  transmute(#tau,
            dlny_da = adults/(1-y.month),
            dlny_dk = kids/(1-y.month)) %>%
  t()

coef_subset <- ghs_tidy_fit %>%
  filter(term %in%  c("adults","kids","y.month"),
         tau %in% c("0.15","0.3","0.45","0.6","0.75")
         ) %>%
  dplyr::select(tau,term,estimate) %>%
  pivot_wider(
    names_from = term,
    values_from = estimate
  )

ghs_change <- coef_subset %>%
  transmute(#tau,
            dlny_da = adults/(1-y.month),
            dlny_dk = kids/(1-y.month)) %>%
  t()

change_tab <- rbind(lcs_change,
                    ghs_change)

rownames(change_tab) = c("Adult change",
                          "Child change",
                          "Adult change",
                          "Child change")

kable(change_tab, format = "latex", align='rrrrr',
      row.names = T, digits = 2,
      booktabs=TRUE, escape=FALSE, longtable=FALSE,
      linesep="",
      caption="Estimated change in required minimum income per adult/child at different quantiles of the required minimum income distribution",
      col.names=c("","$\\tau$ = 0.15",  "$\\tau$ = 0.3", "$\\tau$ = 0.45", "$\\tau$ = 0.6", "$\\tau$ = 0.75")) %>%
#  add_header_above(c(" "=1, "Living Conditions" = 2, "General Household" = 2)) %>%
  pack_rows("Living Conditions Survey 2014/15", 1, 2) %>%
  row_spec(2, hline_after = TRUE) %>%
  pack_rows("General Household Survey 2023", 3,4) %>%
  #row_spec(34, hline_after = TRUE) %>%
  kable_styling(latex_options = c("striped", "hold_position", position="center")) %>%
  footnote(general = "Estimated changes in required minimum income at the household level per adult or child across quantiles of required minimum income; only a subset of quantiles are reported in the table.", escape=FALSE, general_title="",threeparttable=TRUE) 
  
```

These parameters can be used to estimate both the underlying poverty lines and changes in the minimum required income per adult and per child -- see equation \eqref{eq:linear-spl} and the implied derivative with respect to adults and children -- at different quantiles of minimum required income. At this point, we report only the changes over a subset of quantiles in Table \@ref(tab:quant-tab). The estimates suggest that the minimum required income per adult/child is higher in 2023 than it was in 2014/15. The range of estimates for children is R110 to R380 in 2014/15, given the chosen quantiles,  but from R300 to R2 818 in 2023. Applying a 50% inflation factor to the LCS data would only yield R165 to R570 for children; thus, the estimated increase per child is substantially greater than that implied by inflation. For adults, the range is R35 to R550 (R50 to R825 after the 50% inflation adjustment) in 2014/15, compared to R250 to R1 787 in 2023; again, the estimated increase per adult far exceeds the inflation adjustment applied to the 2014/15 data. 


## Potential endogeneity


```{r lcs_hetiv, dependson="lcs; model-formulas"}

lcs_data <- lcs2014 %>%
  filter(minq <= quantile(minq, 0.95, na.rm = TRUE),
         minq >= quantile(minq, 0.05, na.rm = TRUE))

lcs_base <- lm(ysmooth,
               data=lcs_data)
# Cluster-robust vcov
vcov_cluster <- vcovCL(lcs_base, cluster = lcs_data$psu)
# Coefficient test with clustered SEs
ct <- coeftest(lcs_base, vcov = vcov_cluster)
# Convert to tidy tibble
tidy_base <- tidy(ct)

theta = tidy_base$estimate[4] 
#ifelse(tidy_base$p.value[4] > 0.05,
#               0, tidy_base$estimate[4])
phi = tidy_base$estimate[3]
#ifelse(tidy_base$p.value[3] > 0.05,
#               0, tidy_base$estimate[3])
one_beta = 1-tidy_base$estimate[2]
#1-ifelse(tidy_base$p.value[2] > 0.05,
#                  0, tidy_base$estimate[2])              

k0 = theta/one_beta
a0 = phi/one_beta

lcs_kidiv <- hetErrorsIV(minq ~ y.month + adults +  age + 
                           age.sq + hhh.male + ethnic + province +
                           settle + marital + education + month +
                           grants + kids | kids | 
                           IIV(age, grants, y.month),
                         data=lcs_data, 
                         verbose = FALSE)
# Cluster-robust vcov
vcov_cluster <- vcovCL(lcs_kidiv, cluster = lcs_data$psu)
# Coefficient test with clustered SEs
ct <- coeftest(lcs_kidiv, vcov = vcov_cluster)
# Convert to tidy tibble
tidy_kids <- tidy(ct)

kk = which(tidy_kids$term=="kids")
aa = which(tidy_kids$term=="adults")
yy = which(tidy_kids$term=="y.month")

theta = tidy_kids$estimate[kk]
#ifelse(tidy_kids$p.value[kk] > 0.05,
#               0, tidy_kids$estimate[kk])
phi = tidy_kids$estimate[aa]
#ifelse(tidy_kids$p.value[aa] > 0.05,
 #              0, tidy_kids$estimate[aa])
one_beta = 1-tidy_kids$estimate[yy]
#ifelse(tidy_kids$p.value[yy] > 0.05,
#                  0, tidy_kids$estimate[yy])              

k1 = theta/one_beta
a1 = phi/one_beta

lcs_adiv <- hetErrorsIV(minq ~ y.month + kids +  age + 
                           age.sq + hhh.male + ethnic + province +
                           settle + marital + education + month +
                           grants + adults | adults | 
                           IIV(age, grants, y.month),
                         data=lcs_data, 
                         verbose = FALSE)
# Cluster-robust vcov
vcov_cluster <- vcovCL(lcs_adiv, cluster = lcs_data$psu)
# Coefficient test with clustered SEs
ct <- coeftest(lcs_adiv, vcov = vcov_cluster)
# Convert to tidy tibble
tidy_adults <- tidy(ct)

kk = which(tidy_adults$term=="kids")
aa = which(tidy_adults$term=="adults")
yy = which(tidy_adults$term=="y.month")

theta = tidy_adults$estimate[kk]
#ifelse(tidy_kids$p.value[kk] > 0.05,
#               0, tidy_kids$estimate[kk])
phi = tidy_adults$estimate[aa]
#ifelse(tidy_kids$p.value[aa] > 0.05,
 #              0, tidy_kids$estimate[aa])
one_beta = 1-tidy_adults$estimate[yy]
#ifelse(tidy_kids$p.value[yy] > 0.05,
#                  0, tidy_kids$estimate[yy])               

k2 = theta/one_beta
a2 = phi/one_beta

#Het IV fails, because I do not have heteroskedasiticity with age and grants
lcs_lnyiv <- ivreg(
  lnminq ~ adults + kids + age + age.sq + hhh.male + 
    ethnic + province + settle + marital + education + 
    month + grants + y.month |
    adults + kids + age + age.sq + hhh.male + ethnic + province +
    settle + marital + education + month + grants + x.month,
  data = lcs_data
)

# Cluster-robust vcov
vcov_cluster <- vcovCL(lcs_lnyiv, cluster = lcs_data$psu)
# Coefficient test with clustered SEs
ct <- coeftest(lcs_lnyiv, vcov = vcov_cluster)
# Convert to tidy tibble
tidy_lny <- tidy(ct)

kk = which(tidy_lny$term=="kids")
aa = which(tidy_lny$term=="adults")
yy = which(tidy_lny$term=="y.month")

theta = tidy_lny$estimate[kk]
#ifelse(tidy_kids$p.value[kk] > 0.05,
#               0, tidy_kids$estimate[kk])
phi = tidy_lny$estimate[aa]
#ifelse(tidy_kids$p.value[aa] > 0.05,
 #              0, tidy_kids$estimate[aa])
one_beta = 1-tidy_lny$estimate[yy]
#ifelse(tidy_kids$p.value[yy] > 0.05,
#                  0, tidy_kids$estimate[yy])                

k3 = theta/one_beta
a3 = phi/one_beta

a = cbind(a0,a1,a2,a3)
k = cbind(k0,k1,k2,k3)

lcs_tab = rbind(a,k)
```

```{r ghs_hetiv, dependson="ghs; model-formulas"}

ghs_data <- ghs2023 %>%
  filter(minq <= quantile(minq, 0.95, na.rm = TRUE),
         minq >= quantile(minq, 0.05, na.rm = TRUE)) %>%
  # categorical "x" values, not really useful as CF
  mutate(lnx = as.numeric(x)) 
#%>%
 # filter(lnx < 13)

ghs_base <- lm(ysmooth,
               data=ghs_data)
# Cluster-robust vcov
vcov_cluster <- vcovCL(ghs_base, cluster = ghs_data$psu)
# Coefficient test with clustered SEs
ct <- coeftest(ghs_base, vcov = vcov_cluster)
# Convert to tidy tibble
tidy_base <- tidy(ct)

theta = tidy_base$estimate[4]
#ifelse(tidy_base$p.value[4] > 0.05,
#               0, tidy_base$estimate[4])
phi = tidy_base$estimate[3]
#ifelse(tidy_base$p.value[3] > 0.05,
#               0, tidy_base$estimate[3])
one_beta = 1-tidy_base$estimate[2]
#ifelse(tidy_base$p.value[2] > 0.05,
#                  0, tidy_base$estimate[2])              

k0 = theta/one_beta
a0 = phi/one_beta

ghs_kidiv <- hetErrorsIV(minq ~ y.month + adults +  age + 
                           age.sq + hhh.male + ethnic + province +
                           settle + marital + education + month +
                           grants + kids | kids | 
                           IIV(age, grants, y.month),
                         data=ghs_data, 
                         verbose = FALSE)
# Cluster-robust vcov
vcov_cluster <- vcovCL(ghs_kidiv, cluster = ghs_data$psu)
# Coefficient test with clustered SEs
ct <- coeftest(ghs_kidiv, vcov = vcov_cluster)
# Convert to tidy tibble
tidy_kids <- tidy(ct)

kk = which(tidy_kids$term=="kids")
aa = which(tidy_kids$term=="adults")
yy = which(tidy_kids$term=="y.month")

theta = tidy_kids$estimate[kk]
#ifelse(tidy_kids$p.value[kk] > 0.05,
#               0, tidy_kids$estimate[kk])
phi = tidy_kids$estimate[aa]
#ifelse(tidy_kids$p.value[aa] > 0.05,
#               0, tidy_kids$estimate[aa])
one_beta = 1-tidy_kids$estimate[yy]
#ifelse(tidy_kids$p.value[yy] > 0.05,
#                  0, tidy_kids$estimate[yy])              

k1 = theta/one_beta
a1 = phi/one_beta

ghs_adiv <- hetErrorsIV(minq ~ y.month  + kids +  age + 
                           age.sq + hhh.male + ethnic + province +
                           settle + marital + education + month +
                           grants + adults | adults | 
                           IIV(age, grants, y.month),
                         data=ghs_data, 
                         verbose = FALSE)
# Cluster-robust vcov
vcov_cluster <- vcovCL(ghs_adiv, cluster = ghs_data$psu)
# Coefficient test with clustered SEs
ct <- coeftest(ghs_adiv, vcov = vcov_cluster)
# Convert to tidy tibble
tidy_adults <- tidy(ct)

kk = which(tidy_adults$term=="kids")
aa = which(tidy_adults$term=="adults")
yy = which(tidy_adults$term=="y.month")

theta = tidy_adults$estimate[kk]
#ifelse(tidy_adults$p.value[kk] > 0.05,
#               0, tidy_adults$estimate[kk])
phi = tidy_adults$estimate[aa]
#ifelse(tidy_adults$p.value[aa] > 0.05,
#               0, tidy_adults$estimate[aa])
one_beta = 1-tidy_adults$estimate[yy]
#ifelse(tidy_adults$p.value[yy] > 0.05,
#                  0, tidy_adults$estimate[yy])              

k2 = theta/one_beta
a2 = phi/one_beta

## Heteroscedasticity fails, so just using IV
ghs_lnyiv <- ivreg(
  lnminq ~ adults + kids + age + age.sq + hhh.male + 
    ethnic + province + settle + marital + education + 
    month + grants + y.month |
    adults + kids + age + age.sq + hhh.male + ethnic + province +
    settle + marital + education + month + grants + x,
  data = ghs_data
)

# Cluster-robust vcov
vcov_cluster <- vcovCL(ghs_lnyiv, cluster = ghs_data$psu)
# Coefficient test with clustered SEs
ct <- coeftest(ghs_lnyiv, vcov = vcov_cluster)
# Convert to tidy tibble
tidy_lny <- tidy(ct)

kk = which(tidy_lny$term=="kids")
aa = which(tidy_lny$term=="adults")
yy = which(tidy_lny$term=="y.month")

theta = tidy_lny$estimate[kk]
#ifelse(tidy_lny$p.value[kk] > 0.05,
#               0, tidy_lny$estimate[kk])
phi = tidy_lny$estimate[aa]
#ifelse(tidy_lny$p.value[aa] > 0.05,
#               0, tidy_lny$estimate[aa])
one_beta = 1-tidy_lny$estimate[yy]
#ifelse(tidy_lny$p.value[yy] > 0.05,
 #                 0, tidy_lny$estimate[yy])              

k3 = theta/one_beta
a3 = phi/one_beta

a = cbind(a0,a1,a2,a3)
k = cbind(k0,k1,k2,k3)

ghs_tab = rbind(a,k)
```


We are concerned with three potential sources of endogeneity. There are potential unobserved factors that correlate with household income, the number of children and the number of adults in the household. Given three potential sources of endogeneity, it would be ideal to incorporate three instruments. Uncovering one instrument is difficult -- finding three is unrealistic. Therefore, we undertake a triangulation exercise, examining the results that would arise under the assumption that only one of the three variables is endogenous at any one time.

As noted earlier, the literature has suggested that household size is partly affected by grant access - a variable we incorporated into the analysis; in our view, it is not likely to meet the exclusion restriction, since grants are a form of income, and are, therefore, likely to correlate directly with required income. Within South Africa, grants are strongly linked to age. However, age is expected to directly influence minimum income requirements through its proximate relationship with life experience. Although using such variables directly is problematic, we use their demeaned values along with that of income, to capture heteroskedasticity and identify the model parameters, as suggested by @Lewbel2012.


```{r endog-tab, dependson="lcs_hetiv;ghs_hetiv", results="asis"}

results.tab = rbind(lcs_tab,ghs_tab)
rownames(results.tab) = c("Adult change",
                          "Child change",
                          "Adult change",
                          "Child change")

kable(results.tab, format = "latex", align='rrrr',
      row.names = T, digits = 2,
      booktabs=TRUE, escape=FALSE, longtable=FALSE,
      linesep="",
      caption="Estimated required minimum income per adult/child with and without endogeneity correction based on linear models",
      col.names=c("Uncorrected",  "Child Endog", "Adult Endog", "Income Endog")) %>%
#  add_header_above(c(" "=1, "Living Conditions" = 2, "General Household" = 2)) %>%
  pack_rows("Living Conditions Survey 2014/15", 1, 2) %>%
  row_spec(2, hline_after = TRUE) %>%
  pack_rows("General Household Survey 2023", 3,4) %>%
  #row_spec(34, hline_after = TRUE) %>%
  kable_styling(latex_options = c("striped", "hold_position", position="center")) %>%
  footnote(general = "Estimated changes in required minimum income at the household level per adult or child, depending on whether none (uncorrected), adults (adult endog), children (child endog) or income (income endog) was treated as a potentially endogenous variable. Parameter estimates were clustered. Endogeneity corrections based on heteroskedastic IV, where the age of the household head, (log) household income - except when income was treated as endogenous - and the number of grants in the household were demeaned for the IV estimate. When income was treated as endogenous, a measure of expenditure is used as an instrument.", escape=FALSE, general_title="",threeparttable=TRUE) 
```

We further use those parameters to estimate the change in minimum required income per child/adult arising from the model. These results are reported in Table \@ref(tab:endog-tab). The table contains four rows, two each for the two different surveys, and, within a survey, one for the child 'effect' and one for the 'adult' effect. The first column of Table \@ref(tab:endog-tab) represents the estimate from an uncorrected model. The second column assumes that the number of adults in the household is endogenous, correcting for that using the @Lewbel2012 heteroskedasticity instrument method; the third column assumes that, instead, the number of children are endogenous and uses the same estimator. The last column reports results based on the assumption that income is the endogenous variable, but estimation is based on standard IV, where expenditure is used as an instrument for income. 

The results in the table suggest a wide range of results. For the uncorrected model (LCS 2014/15), we estimate the required minimum income per adult and child to be R240 and R370, respectively; this lies somehwere between the 0.6 and 0.75 quantile results in Table \@ref(tab:quant-tab). Applying heteroskedasticity IV, first for potential endogeneity in the number of children, led to similar adult "costs", but a child "cost" reduction of approximately one-half. Treating adults as the endogenous regressor further reduced the child cost, but increased the adult cost by nearly a factor of four. Treating income as endogenous, however, led to the elimination of all child and adult costs. Whether expenditure is a reasonable instrument, despite meeting standard endogeneity test expectations, is open to debate.

Similar to what was observed for the LCS data, we find that treating income as an endogenous variable using the GHS data reduces the minimum required income per adult/child to zero. On the other hand, applying @Lewbel2012 to the number of children in the household increases required income per child by a factor of seven, but slightly reduces the adult effect. When applying @Lewbel2012 to the adults, it is the adult effect that increases by a factor of three, while the child effect remains similar. 

Although @koch2022 uncovers some changes in underlying equivalence scales following endogeneity correction, they are not on the same scale as is observed here. Despite the scale of the possible endogeneity effects, we continue to make use of the uncorrected results. They are a reasonable lower bound on the additional required minimum income per adult/child. Thus, they also represent a reasonable lower bound for the calculation of subjective poverty lines. Although we estimate zeroes when we correct for endogeneity in income, expenditure may not be an appropriate instrument, when the exclusion restriction is taken into consideration. Minimum required income is likely to be influenced by expenditure patterns in the household, as at least some of that income must be used to cover some proportion of the expenditures.

# Subjective poverty 
 
From our results, we have observed that required minimum income is increasing in the number of adults and children, such that required income increases with household size. As already noted, the required income gradient per child and adult is increasing over time; so is its proportionality to actual income. Each of these implies larger subjective poverty lines over time. However, the intercept is lower in 2023 than in 2014 -- a lower intercept reduces the reference level for subjective poverty.^[In results not shown, the intercept was estimated to be negative in 2023, when the data was not trimmed. Furthermore, it resulted in negative subjective poverty lines for non-child households. Once the data was trimmed, the intercept became positive in sign, and the resulting poverty lines also became positive.] 

## Poverty lines

In other words, whether the subjective lines are higher or lower in 2023 is an empirical question, and, therefore, we will compute the lines for both surveys. See Table \@ref(tab:spl-table) for those computations. The table contains direct estimates from the LCS data, as well as inflation-adjusted values from the same; the adjustment is 150% larger than the direct values. It also includes direct estimates from the GHS data. For adult-only households in the LCS, poverty lines are higher than for similar households in the GHS -- here the comparison is inflation adjusted LCS to direct GHS, while LCS poverty lines are usually lower for four-child households. For the rest of the household types, the pattern is nuanced: often smaller households will have lower LCS lines, while the opposite is true for larger households.

Although it is somewhat difficult to ascertain a pattern from the subjective poverty lines, part of that is due to the 150% inflation adjustment applied to the 2014/15 data. Of more relevance, however, is whether the poverty rates have increased or decreased, for which types of households over time and how that relates to the money-metric poverty lines employed by Statistics South Africa. We now turn to these issues.

## Subjectively poor vs NT objectively poor?

Tables \@ref(tab:poor-data) and \@ref(tab:poor-data-ghs) present a range of in-sample poverty estimates. Each table contains 5 columns, three based on subjective measures: (i) whether the household income is at least as large as its minimum requirement, (ii) whether its income exceeds the linear model determined subjective poverty line, and (iii) whether its income exceeds the quadratic model determined subjective poverty line. There are also two objective measures, (iv) whether per capita household income meets the per capita lower bound national poverty line and (v) whether per capita household income meets the per capita upper bound national poverty line. 

As expected, since the lower bound objective poverty line is lower than the upper bound poverty line, poverty rates are always higher under the upper bound. With the LCS data, the lowest lower bound poverty rate is less than 10% of the relevant households (2 adults and no children). With the GHS data, the lowest (lower bound) rate is 15.3% for single adult households. 

```{r lineary-spl-smooth, dependson="lcs-sub; lcs; model-formulas"}

base.data <- lcs2014 %>%
  filter(minq <= quantile(minq, 0.95, na.rm = TRUE),
         minq >= quantile(minq, 0.05, na.rm = TRUE))

model <- lm(ysmooth,
            data=base.data)

b <- coef(model)[1:4] # does not count non-income and non-adult/child vars.
b1 <- b[3:4]          # just the kids and adult bit
denom <- 1-b[2]

dfdiff <- akmat %>% dplyr::select(adults, kids) %>%
  as.matrix()

spl.base <-   (b[1] + (dfdiff %*% b1)) * (1/denom) 

spl.lin.yall <- akmat %>%
  add_column(spl.linear = as.integer(spl.base)) 

spl.lin.yall.table <- spl.lin.yall %>%
  rename("spl" = "spl.linear") 

spl.lin.yall.50 <-akmat %>%
  dplyr::select(adults,kids) %>%
  add_column(spl.linear = 1.5*as.integer(spl.base)) 

spl.lin.yall.table.50 <- spl.lin.yall.50 %>%
  rename("spl" = "spl.linear") 

```


```{r quady-spl-smooth, dependson="lcs-sub; lcs; model-formulas"}

base.data <- lcs2014 %>%
  filter(minq <= quantile(minq, 0.95, na.rm = TRUE),
         minq >= quantile(minq, 0.05, na.rm = TRUE))

model <- lm(quad,
            data=base.data)

b <- coef(model)[1:5] # does not count non-income and non-adult/child vars.
b1 <- b[4:5]          # just the kids and adult bit


dfdiff <- akmat %>% dplyr::select(adults,kids) %>%
  as.matrix()

# This calculates for all household types at once... but no real roots?
c <- (b[1] + (dfdiff %*% b1))
bb <- b[2] - 1
a <- b[3]

discriminant <- (bb^2) - (4*a*c)

# How to choose?
root1 <- (-bb + sqrt(discriminant))*(1/(2*a))
root2 <- (-bb - sqrt(discriminant))*(1/(2*a))

# do not understand why not working?
spl.base <-   root2 

spl.quad.yall <- akmat %>%
  dplyr::select(adults,kids) %>%
  add_column(spl.quad = as.integer(spl.base))

spl.quad.yall.table <- spl.quad.yall %>%
  rename("spl" = "spl.quad") 

spl.quad.yall.50 <- akmat %>%
  dplyr::select(adults,kids) %>%
  add_column(spl.quad = 1.5*as.integer(spl.base))

spl.quad.yall.table.50 <- spl.quad.yall.50 %>%
  rename("spl" = "spl.quad") 


```

```{r lineary-spl-smooth-ghs, dependson="lcs-sub; ghs; model-formulas"}

base.data <- ghs2023 %>%
  filter(minq <= quantile(minq, 0.95, na.rm = TRUE),
         minq >= quantile(minq, 0.05, na.rm = TRUE))

model <- lm(ysmooth,
            data=base.data)

b <- coef(model)[1:4] # does not count non-income and non-adult/child vars.
b1 <- b[3:4]          # just the kids and adult bit
denom <- 1-b[2]

dfdiff <- akmat %>% dplyr::select(adults,kids) %>% 
  as.matrix()

spl.base <-   (b[1] + (dfdiff %*% b1)) * (1/denom) 

spl.lin.yall.2023 <- akmat %>%
  dplyr::select(adults,kids) %>%
  add_column(spl.linear = as.integer(spl.base)) 

spl.lin.yall.table.2023 <- spl.lin.yall.2023 %>%
  rename("spl" = "spl.linear") 

spl.lin.yall.2023.50 <- akmat %>%
  dplyr::select(adults,kids) %>%
  add_column(spl.linear = 0.5*as.integer(spl.base)) 

spl.lin.yall.table.2023.50 <- spl.lin.yall.2023.50 %>%
  rename("spl" = "spl.linear") 


```

```{r quady-spl-smooth-ghs, dependson="lcs-sub; ghs; model-formulas"}

base.data <- ghs2023 %>%
  filter(minq <= quantile(minq, 0.95, na.rm = TRUE),
         minq >= quantile(minq, 0.05, na.rm = TRUE))

model <- lm(quad,
            data=base.data)

b <- coef(model)[1:5] # does not count non-income and non-adult/child vars.
b1 <- b[4:5]          # just the kids and adult bit


dfdiff <- akmat %>% dplyr::select(adults,kids) %>% 
  as.matrix()

# This calculates for all household types at once... but no real roots?
c <- (b[1] + (dfdiff %*% b1))
bb <- b[2] - 1
a <- b[3]

discriminant <- (bb^2) - (4*a*c)

# How to choose?
root1 <- (-bb + sqrt(discriminant))*(1/(2*a))
root2 <- (-bb - sqrt(discriminant))*(1/(2*a))

# do not understand why not working?
spl.base <-   root2 

spl.quad.yall.2023 <- akmat %>%
  dplyr::select(adults,kids) %>%
  add_column(spl.quad = as.integer(spl.base))

spl.quad.yall.table.2023 <- spl.quad.yall.2023 %>%
  rename("spl" = "spl.quad")

spl.quad.yall.2023.50 <- akmat %>%
  dplyr::select(adults,kids) %>%
  add_column(spl.quad = 0.5*as.integer(spl.base))

spl.quad.yall.table.2023.50 <- spl.quad.yall.2023.50 %>%
  rename("spl" = "spl.quad")


```


```{r poor-data, dependson="lcs; lineary-spl-smooth; quady-spl-smooth", results="asis"}


# This builds out a simple table...
# How do we want to use this?
poor.data <- left_join(lcs2014, spl.lin.yall,
                       by = c("adults","kids")) %>%
  left_join(spl.quad.yall, by = c("adults","kids")) %>%
  mutate(hhsize = adults + kids,
         lbpoverty = hhsize * 647,
         ubpoverty = hhsize * 992,
         y = y.month,
         x = x.month) %>%
  group_by(adults,kids) %>%
  summarise(own.subj.poor = round(100*sum(lny < lnminq)/n(),2),
            lin.subj.poor = round(100*sum(y < spl.linear)/n(),2),
            quad.subj.poor = round(100*sum(y < spl.quad)/n(),2),
            obj.poor.lb = round(100*sum(y < lbpoverty)/n(),2),
            obj.poor.ub = round(100*sum(y < ubpoverty)/n(),2)) %>%
  ungroup() 

  #
  
kable(poor.data, format = "latex", align='rrrrrrr',
      row.names = F,
      booktabs=TRUE, escape=FALSE, longtable=TRUE,
      linesep="",
      caption="Precentage of poor households by household structure type based on subjective and objective poverty lines from the Living Conditions Survey 2014-15",
      col.names=c("Adults","Kids", "Own Value","Linear","Quadratic","Lower","Upper")) %>%
  add_header_above(c(" "=2, "Subjective Povery"=3, "Objective Poverty" = 2)) %>%
  kable_styling(latex_options = c("striped", "hold_position", position="center")) %>%
  footnote(general = "Estimated poverty percentages based on subjective poverty lines underscored by linear and quadratic estimates of minimum income levels compared to lower (ZAR 647 per capita in 2014) and upper bound poverty (ZAR 992 per capita) lines from national treasury. Percentages not weighted to the population. Own value represents the percentage of people whose reported income is exceeded by their reported minimum required income.", escape=FALSE, general_title="",threeparttable=TRUE) 


```


```{r poor-data-ghs, dependson="ghs; lineary-spl-smooth-ghs; quady-spl-smooth-ghs", results="asis"}

# This builds out a simple table...
# How do we want to use this?
poor.data <- left_join(ghs2023, spl.lin.yall.2023,
                       by = c("adults","kids")) %>%
  left_join(spl.quad.yall.2023, by = c("adults","kids")) %>%
  mutate(hhsize = adults + kids,
         lbpoverty = hhsize * 1058,
         ubpoverty = hhsize * 1558,
         y = y.month) %>%
  group_by(adults,kids) %>%
  summarise(own.subj.poor = round(100*sum(lny < lnminq)/n(),2),
            lin.subj.poor = round(100*sum(y < spl.linear)/n(),2),
            quad.subj.poor = round(100*sum(y < spl.quad)/n(),2),
            obj.poor.lb = round(100*sum(y < lbpoverty)/n(),2),
            obj.poor.ub = round(100*sum(y < ubpoverty)/n(),2)) %>%
  ungroup() 

kable(poor.data, format = "latex", align='rrrrrrr',
      row.names = F,
      booktabs=TRUE, escape=FALSE, longtable=TRUE,
      linesep="",
      caption="Precentage of poor households by household structure type based on subjective and objective poverty lines from the General Household Survey 2023",
      col.names=c("Adults","Kids", "Own Value","Linear","Quadratic","Lower","Upper")) %>%
  add_header_above(c(" "=2, "Subjective Poverty"=3, "Objective Poverty" = 2)) %>%
  kable_styling(latex_options = c("striped", "hold_position", position="center")) %>%
  footnote(general = "Estimated poverty percentages based on subjective poverty lines underscored by linear and quadratic estimates of minimum income levels compared to lower (ZAR 1058 per capita in 2023) and upper bound poverty (ZAR 1558 per capita) lines from national treasury. Percentages not weighted to the population. Own value represents the percentage of people whose reported income is exceeded by their reported minimum required income.", escape=FALSE, general_title="",threeparttable=TRUE) 


```

In terms of subjective poverty rates, we find that they tend to be much higher for smaller households, and that the rates are mostly lower for larger households, although that pattern is not monotonic. Furthermore, for households with fewer children, we tend to find higher subjective poverty rates than objective poverty rates. Once the number of adults reaches five, objective rates are at least as high or higher than the subjective rates.

# Conclusion

In this research, we applied a variety of models to two different datasets, to estimate the determinants of minimum required income in the household. We used those estimates to calculate subjective poverty lines, underpinned by the intersection method. We also compared those lines over time, appropriately adjusting for inflation. We then compared the poverty rates that would arise from the application of those poverty lines to the samples that were used for estimation, comparing those rates with what would arise if comparing money-metric rates.

The results suggest that the subjective pverty lines and rates differ over time compared to each other and compared to objective measures generally applied in South Africa. The differences are nuanced. Yes, certain types of households always fair worse under one type of measure or at one point in time; however, there are few obvious patterns or household size gradients in the results to suggest that a per capita money-metric measure properly captures poverty across a wide spectrum of the South African population. Although per capita measures are easy to determine and communicate, they are at best 'blunt' weapons in a complicated measurement exercise. 

A wide variety of subjective data is available across many household surveys in South Africa and elsewhere. This includes consumption adequacy questions, income satisfaction questions, socioeconomic ladder questions, and the MIQ considered here. In addition, there is research on SPNs. To develop a more representative poverty line, we would suggest further research attempting to capture the breadth and depth of as many subjective measures as possible. One option is to develop additional multidimensional indexes [@AlkireFoster2011], extending the work of @Finn2013MDP and @OmotosoKoch2018ChildMPI, amongst others; however, those indexes are driven by arbitrary cut-offs. Reducing the arbitrariness of the cut-off decisions made by researchers and applied when estimating subjective poverty is worthy of additional effort.



\newpage
\singlespacing
# References {-}
<div id="refs"></div>

\doublespacing

\newpage
\appendix

\setcounter{figure}{0}
\renewcommand\thefigure{\Alph{section}.\arabic{figure}} 
  
\setcounter{table}{0}
\renewcommand\thetable{\Alph{section}.\arabic{table}} 

\setcounter{equation}{0}
\renewcommand\theequation{\Alph{section}.\arabic{equation}}

# Descriptive Statistics


```{r dstat, dependson="lcs", results="asis"}

# create a factor to split on for comparison
# For fun, I dropped equality, but did not lose many 
# --  9 have the exact same...
All <- lcs2014 %>%
  mutate(lnylnminq = as_factor(
    case_when(
     lny < lnminq ~ "Too little",
     lny >= lnminq ~ "Enough"
  )),
  adults = as.numeric(adults),
  kids = as.numeric(kids)) %>%
  filter(y.month <= quantile(y.month, 0.95, na.rm = TRUE),
         y.month >= quantile(y.month, 0.05, na.rm = TRUE)) %>%
  droplevels()


our.sum.description <- list(
  "Population Group" = 
    list("African" = ~ only_perc(ethnic=="African/Black"),
         "Mixed" = ~ only_perc(ethnic=="Coloured"),
         "Asian" = ~ only_perc(ethnic=="Indian/Asian"),
         "White" = ~ only_perc(ethnic=="White")),
  "Marital Status" = 
    list("Marrried" = ~ only_perc(marital=="Married"),
         "Partners" = ~ only_perc(marital=="Living together as married partners"),
         "Never married" = ~ only_perc(marital=="Never married"),
         "Widowed" = ~ only_perc(marital=="Widower/Widow"),
         "Separate" = ~ only_perc(marital=="Separated"),
         "Divorced" = ~ only_perc(marital=="Divorced")),
  "Education" = 
    list("No schooling" = ~ only_perc(education=="none"),
         "Some schooling" = ~ only_perc(education=="nqf0"),
         "Completed grade 9" = ~ only_perc(education=="nqf1"),
         "Completed grade 10" = ~ only_perc(education=="nqf2"),
         "Completed grade 11" = ~ only_perc(education=="nqf3"),
         "Completed grade 12" = ~ only_perc(education=="nqf4"),
         "First year university" = ~ only_perc(education=="nqf5"),
         "Second year university" = ~ only_perc(education=="nqf6"),
         "Completed university" = ~ only_perc(education=="nqf7"),
         "Completed honours" = ~ only_perc(education=="nqf8"),
         "Further postgraduate" = ~ only_perc(education=="nqf9-10")),
  "Residence" = 
    list("Urban formal" = ~ only_perc(settle=="Urban Formal"),
         "Urban informal" = ~ only_perc(settle=="Urban Informal"),
         "Traditional area" = ~ only_perc(settle=="Traditional Area"),
         "Rural formal" = ~ only_perc(settle=="Rural Formal")),
  "Province" = 
    list("Western Cape" = ~ only_perc(province=="Western Cape"),
         "Eastern Cape" = ~ only_perc(province=="Eastern Cape"),
         "Northern Cape" = ~ only_perc(province=="Northern Cape"),
         "Free State" = ~ only_perc(province=="Free State"),
         "KwaZulu-Natal" = ~ only_perc(province=="Kwazulu Natal"),
         "North West" = ~ only_perc(province=="North West"),
         "Gauteng" = ~ only_perc(province=="Gauteng"),
         "Mpumalanga" = ~ only_perc(province=="Mpumalanga"),
         "Limpopo" = ~ only_perc(province=="Limpopo")),
  "Household Head Age" = 
    list("mean (sd)" = ~ qwraps2::mean_sd(age, denote_sd="paren")),
  "Household Composition" = 
    list("Children: mean (sd)" = ~ qwraps2::mean_sd(kids, denote_sd="paren"),
         "Adults: mean (sd)" = ~ qwraps2::mean_sd(adults, denote_sd="paren")),
 "Income and Expenditure" = 
   list("Expenditure: mean (sd)" = ~ qwraps2::mean_sd(x.month, denote_sd="paren"),
        "Income: mean (sd)" = ~ qwraps2::mean_sd(y.month, denote_sd="paren"),
        "Minimum income: mean (sd)" = ~ qwraps2::mean_sd(minq, denote_sd="paren"))
)


our.sum.adequate <- qwraps2::summary_table(dplyr::group_by(All,lnylnminq), our.sum.description)
our.sum.total <- qwraps2::summary_table(All,our.sum.description)

our.sum.table <- cbind(our.sum.total, our.sum.adequate)

print(our.sum.table, vline="", align="l|rrr",longtable=TRUE,booktabs=T,linesep="",
      caption="Summary statistics of household or household head overall and by income adequacy. \\footnotesize{Note: Categorical variables are presented as the percent of observations in each category within each column. For continuous variables, the mean is presented with its standard deviation, separated by $\\pm$. All represents the entire database, Enough represents household's whose reported minimum income is not less than their actual, and Too little represents those whose reported minimum income exceeds their actual.}",
      rtitle= "\\bf{Adequate income}"
      #cnames = c("\\multicolumn{3}{c}{Food Adequacy}")
      )


```

```{r dstat-ghs, dependson="ghs", results="asis"}

# create a factor to split on for comparison
# For fun, I dropped equality, but did not lose many 
# --  9 have the exact same...
All <- ghs2023 %>%
  mutate(lnylnminq = as_factor(
    case_when(
      lny < lnminq ~ "Too little",
      lny >= lnminq ~ "Enough"
    )),
    adults = as.numeric(adults),
    kids = as.numeric(kids))  %>%
  filter(y.month <= quantile(y.month, 0.95, na.rm = TRUE),
         y.month >= quantile(y.month, 0.05, na.rm = TRUE)) %>%
  droplevels()


our.sum.description <- list(
  "Population Group" = 
    list("African" = ~ only_perc(ethnic=="1. African/Black"),
         "Mixed" = ~ only_perc(ethnic=="2. Coloured"),
         "Asian" = ~ only_perc(ethnic=="3. Indian/Asian"),
         "White" = ~ only_perc(ethnic=="4. White")),
  "Marital Status" = 
    list("Marrried" = ~ only_perc(marital=="1. Legally married"),
         "Partners" = ~ only_perc(marital=="2. Living together like husband and wife/partners"),
         "Never married" = ~ only_perc(marital=="7. Single and have never been married/never lived together as husband/wife before" |
                                         marital == "6. Single, but have lived together with someone as husband/wife before"),
         "Widowed" = ~ only_perc(marital=="5. Widowed"),
         "Separate" = ~ only_perc(marital=="4. Separated, but still legally married"),
         "Divorced" = ~ only_perc(marital=="3. Divorced")),
  "Education" = 
    list("No schooling" = ~ only_perc(education=="none"),
         "Some schooling" = ~ only_perc(education=="nqf0"),
         "Completed grade 9" = ~ only_perc(education=="nqf1"),
         "Completed grade 10" = ~ only_perc(education=="nqf2"),
         "Completed grade 11" = ~ only_perc(education=="nqf3"),
         "Completed grade 12" = ~ only_perc(education=="nqf4"),
         "First year university" = ~ only_perc(education=="nqf5"),
         "Second year university" = ~ only_perc(education=="nqf6"),
         "Completed university" = ~ only_perc(education=="nqf7"),
         "Completed honours" = ~ only_perc(education=="nqf8"),
         "M Degree" = ~ only_perc(education=="nqf9"),
         "PhD Degree" = ~ only_perc(education=="nqf10")),
  "Residence" = 
    list("Urban" = ~ only_perc(settle=="Urban"),
         "Traditional" = ~ only_perc(settle=="Traditional"),
         "Farms" = ~ only_perc(settle=="Farms")),
  "Province" = 
    list("Western Cape" = ~ only_perc(province=="1. Western Cape"),
         "Eastern Cape" = ~ only_perc(province=="2. Eastern Cape"),
         "Northern Cape" = ~ only_perc(province=="3. Northern Cape"),
         "Free State" = ~ only_perc(province=="4. Free State"),
         "KwaZulu-Natal" = ~ only_perc(province=="5. Kwazulu Natal"),
         "North West" = ~ only_perc(province=="6. North West"),
         "Gauteng" = ~ only_perc(province=="7. Gauteng"),
         "Mpumalanga" = ~ only_perc(province=="8. Mpumalanga"),
         "Limpopo" = ~ only_perc(province=="9. Limpopo")),
  "Household Head Age" = 
    list("mean (sd)" = ~ qwraps2::mean_sd(age, denote_sd="paren")),
  "Household Composition" = 
    list("Children: mean (sd)" = ~ qwraps2::mean_sd(kids, denote_sd="paren"),
         "Adults: mean (sd)" = ~ qwraps2::mean_sd(adults, denote_sd="paren")),
  "Income and Expenditure" = 
    list(#"Expenditure: mean (sd)" = ~ qwraps2::mean_sd(lnx, denote_sd="paren"),
         "Income: mean (sd)" = ~ qwraps2::mean_sd(y.month, denote_sd="paren"),
         "Minimum income: mean (sd)" = ~ qwraps2::mean_sd(minq, denote_sd="paren"))
)


our.sum.adequate <- qwraps2::summary_table(dplyr::group_by(All,lnylnminq), our.sum.description)
our.sum.total <- qwraps2::summary_table(All,our.sum.description)

our.sum.table <- cbind(our.sum.total, our.sum.adequate)

print(our.sum.table, vline="", align="l|rrr",longtable=TRUE,booktabs=T,linesep="",
      caption="Summary statistics of household or household head overall and by income adequacy. \\footnotesize{Note: Categorical variables are presented as the percent of observations in each category within each column. For continuous variables, the mean is presented with its standard deviation, separated by $\\pm$. All represents the entire database, Enough represents household's whose reported minimum income is not less than their actual, and Too little represents those whose reported minimum income exceeds their actual.}",
      rtitle= "\\bf{Adequate income}"
      #cnames = c("\\multicolumn{3}{c}{Food Adequacy}")
)


```

\setcounter{figure}{0}
\renewcommand\thefigure{\Alph{section}.\arabic{figure}} 
  
\setcounter{table}{0}
\renewcommand\thetable{\Alph{section}.\arabic{table}} 

\setcounter{equation}{0}
\renewcommand\theequation{\Alph{section}.\arabic{equation}}

# Subjective poverty line estimates miniumum income questions

```{r spl-table, dependson="lineary-spl-smooth; quady-spl-smooth; lineary-spl-smooth-ghs; quady-spl-smooth-ghs; some-functions", results="asis", size = "footnotesize"}

spl.tab <- cbind(spl.lin.yall.table[,c(1:2,14)], 
                 spl.quad.yall.table[,3],
                 spl.lin.yall.table.50[,3], 
                 spl.quad.yall.table.50[,3],
                 spl.lin.yall.table.2023[,3],
                 spl.quad.yall.table.2023[,3]) 
                 #round( zed[,3:6], digits=0))

kable(spl.tab, format = "latex", align='cccccccc',
      row.names = F, digits = 0,
      booktabs=TRUE, escape=FALSE, longtable=TRUE,
      linesep="",
      caption="Estimate of subjective poverty lines based on minimum household income, underpinned by linear regression model using data from the Living Conditions Survey 2014-15 and the General Household Survey 2023",
      col.names=c("Adults","Kids", "Linear", "Qadratic",
                  "Linear", "Qadratic","Linear", "Qadratic")) %>%
  add_header_above(c(" "=2, "Unadjusted"=2, "Inflation adjusted"=2,
                     "Unadjusted" = 2)) %>%
  add_header_above(c(" "=2, "Living Conditions"=4, "General Household" = 2)) %>%
  kable_styling(latex_options = c("striped", "hold_position", position="center")) %>%
  footnote(general = "Estimated poverty lines by household type (adults and kids), netting out effects related to location, and other household head controls.", escape=FALSE, general_title="",threeparttable=TRUE) 
```

\setcounter{figure}{0}
\renewcommand\thefigure{\Alph{section}.\arabic{figure}} 
  
\setcounter{table}{0}
\renewcommand\thetable{\Alph{section}.\arabic{table}} 

\setcounter{equation}{0}
\renewcommand\theequation{\Alph{section}.\arabic{equation}}

# Linear estimates

```{r smooth-table, dependson="linear-models; linear-models-ghs", results = "asis"}

## dummy rows for squared term..
ddr1 <- c(n="lny.sq",params="b",results = NA)
ddr2 <- c(n="lny.sq",params="s",results = NA)
ddr <- rbind(ddr1, ddr2)

# lcs linear y and smooth a/k
#lcs_ly_smooth_tab 
lcsly <- rbind(lcs_ly_smooth_tab[1:4,],
              ddr,
              lcs_ly_smooth_tab[5:98,])
lcsly_tab <- lcsly[c(1:22,99:100),]

# lcs quadratic y and smooth a/k
#lcs_qy_smooth_tab 
lcsqy_tab <- lcs_qy_smooth_tab[c(1:22,99:100),]

# ghs linear y and smooth a/k
#ghs_ly_smooth_tab 
ghsly <- rbind(ghs_ly_smooth_tab[1:4,],
              ddr,
              ghs_ly_smooth_tab[5:82,])
ghsly_tab <- ghsly[c(1:22,83:84),]

# lcs quadratic y and smooth a/k
#lcs_qy_smooth_tab 
ghsqy_tab <- ghs_qy_smooth_tab[c(1:22,83:84),]

smooth.tab.names <- c("Intercept", "",
                      "Income","","Squared log income", "",
        "Adults in HH","", "Kids in HH","",
        "Age of HH Head","", "Squared age of head","",
        "Female head","", "Coloured head","",
        "Asian head","","White head","",
        "Grants in HH","")
smooth.tab <- tibble(rnames = smooth.tab.names, 
                     ly = lcsly_tab$results, 
                     qy = lcsqy_tab$results,
                     ly23 = ghsly_tab$results, 
                     qy23 = ghsqy_tab$results)


kable(smooth.tab, format = "latex", align='lrrrr',
      row.names = F,
      booktabs=TRUE, escape=FALSE, longtable=TRUE,
      linesep="",
      caption="Effect size estimates for a subsete of controls for (log) reported minimum household income from the Living Conditions Survey 2014-15 and General Household Survey 2023",
      col.names=c("Composition","Linear","Quadratic","Linear","Quadratic")) %>%
  add_header_above(c(" "=1, "Living Conditions" = 2, "General Household" = 2)) %>%
  #pack_rows("Adults and children as continuous variables", 1, 4) %>%
  #row_spec(4, hline_after = TRUE) %>%
  #pack_rows("Adults and children as categorical variables", 5, 22) %>%
  #row_spec(22, hline_after = TRUE) %>%
  kable_styling(latex_options = c("striped", "hold_position", position="center")) %>%
  footnote(general = "Estimated coefficients across surveys.  Models also included province, survey month, head education, marital status and settlement-type fixed effects.", escape=FALSE, general_title="",threeparttable=TRUE) 

```

```{r dummies-table, dependson="linear-models; linear-models-ghs", results = "asis"}

## dummy rows for squared term..
ddr1 <- c(n="lny.sq",params="b",results = NA)
ddr2 <- c(n="lny.sq",params="s",results = NA)
ddr <- rbind(ddr1, ddr2)

# lcs linear y and dummies a/k
#lcs_ly_dummies_tab 
lcsly <- rbind(lcs_ly_dummies_tab[1:4,],
              ddr,
              lcs_ly_dummies_tab[5:112,])
lcsly_tab <- lcsly[c(1:36,113:114),]

# lcs quadratic y and dummies a/k
#lcs_qy_dummies_tab 
lcsqy_tab <- lcs_qy_dummies_tab[c(1:36,113:114),]

# ghs linear y and dummies a/k
#ghs_ly_dummies_tab 
ghsly <- rbind(ghs_ly_dummies_tab[1:4,],
              ddr,
              ghs_ly_dummies_tab[5:96,])
ghsly_tab <- ghsly[c(1:36,97:98),,]

# lcs quadratic y and dummies a/k
#lcs_qy_dummies_tab 
ghsqy_tab <- ghs_qy_dummies_tab[c(1:36,97:98),]

dummies.tab.names <- c("Intercept","",
                       "Income","","Squared log income", "",
                       "One child","","Two children","",
                       "Three children","","Four children","",
                       "Two adults","", "Three adults","",
                       "Four adults","","Five adults","",
                       "Six adults","",
                       "Age of HH Head","", "Squared age of head","",
                       "Female head","", "Coloured head","",
                       "Asian head","","White head","",
                       "Grants in HH","")
dummies.tab <- tibble(rnames = dummies.tab.names, 
                      ly = lcsly_tab$results, 
                      qy = lcsqy_tab$results,
                      ly23 = ghsly_tab$results, 
                      qy23 = ghsqy_tab$results)

kable(dummies.tab, format = "latex", align='lrrrr',
      row.names = F,
      booktabs=TRUE, escape=FALSE, longtable=TRUE,
      linesep="",
      caption="Effect size estimates for a subset of controls on (log) reported minimum household income from the Living Conditions Survey 2014-15 and General Household Survey 2023",
      col.names=c("Composition","Linear","Quadratic","Linear","Quadratic")) %>%
  add_header_above(c(" "=1, "Living Conditions" = 2, "General Household" = 2)) %>%
  #pack_rows("Adults and children as continuous variables", 1, 4) %>%
  #row_spec(4, hline_after = TRUE) %>%
  #pack_rows("Adults and children as categorical variables", 5, 22) %>%
  #row_spec(22, hline_after = TRUE) %>%
  kable_styling(latex_options = c("striped", "hold_position", position="center")) %>%
  footnote(general = "Estimated coefficients across surveys.  Models also included province, survey month, head education, marital status and settlement-type fixed effects.", escape=FALSE, general_title="",threeparttable=TRUE) 

```

